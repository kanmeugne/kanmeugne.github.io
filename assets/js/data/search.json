[ { "title": "Hadoop : Map/Reduce Using Python", "url": "/posts/hadoop-map-reduce-using-python/", "categories": "microservcies", "tags": "apache, docker, solution architect, hive", "date": "2025-09-22 00:00:00 +0800", "snippet": "Hadoop is an affordable, reliable and scalable platform for big data storage and analysis ‚Äì it runs on commodity hardware and it is open source. Technically speaking, the Hadoop platform is the answer to the unevitable question we face one day or another as we live in a data age ‚Äì which is : how do we process tons of data efficiently ? It is not just about storage, but also, and even more, about implementing data processing models that can provide insights to decision makers in a competitive world ‚Äì where everything has to be fast and resilient.There are many important concepts to know in order to understand the hadoop framework ‚Äì in this tutorial we will focus on 2 of them (the interested reader can check this article for an extensive review of hadoop concepts) : Map/Reduce model : a programming model for data processing, inherently parallel, thus putting very large-scale data analysis into the hands of anyone with enough machines at their disposal. Map/Reduce program can be written in several popular languages ‚Äì Java, Python, Ruby etc. ‚Äì or wrapped using distributed tools, like Apache Hive, built on top of the hadoop platform. HDFS : Hadoop comes with a distributed filesystem called HDFS, which stands for Hadoop Distributed Filesystem. HDFS is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardwareKanmeugne‚Äôs Blog ‚Äì Hadoop : Map/Reduce Using PythonIn this tutorial, you‚Äôll learn how to process data in HDFS using Python, and then use Hive to query your results directly from the Hadoop cluster. Whether you‚Äôre new to Hadoop or looking to experiment with distributed data processing and analytics, this tutorial offers a practical, reproducible starting point right from your local machine.Ready to dive in? Just clone the repo, follow the step-by-step instructions, and start exploring big data with Hadoop, MapReduce, and Hive ‚Äî all powered by Docker.How toBuild the applicationThe full code for this tutorial is available from github, you just have to pull and run : Clone and deploy the Hadoop Docker setup: $ git clone https://github.com/kanmeugne/modern-data-architectures.git $ cd modern-data-architectures/handzon-hadoop-python-map-reduce $ docker-compose up -d # [+] Building 0.0s ... # ...This launches namenodes, datanodes, and supporting services in containers. It also creates a hive server, to create and explore an hdfs-compatible database.Add some data in the hdfs serverLet‚Äôs add some data in the distributed filesystem: Copy your CSV file into the namenode container:$ curl -L -o movieratings.csv https://files.grouplens.org/datasets/movielens/ml-100k/u.data$ docker cp movieratings.csv &lt;namenode-container&gt;:/tmp/ # on the docker host The dataset comes from GroupLens, a research lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specializing in recommender systems, online communities, mobile and ubiquitous technologies, digital libraries, and local geographic information systems. Load the CSV into an HDFS folder within the container:$ docker exec &lt;namenode-container&gt; hdfs dfs -mkdir -p /input$ docker exec &lt;namenode-container&gt; hdfs dfs -put /tmp/movieratings.csv /input/ # in the dockerTest the mapper and reducer functions on the hostIt is possible to test the python scripts using the console pipe.$ cat movieratings.csv | python mapper.py | python reducer.py...708 4.0566 4.01010 4.050 5.0134 5.0... Copy the mapper.py and reducer.py files in the namenode container $ docker cp mapper.py &lt;namenode-container&gt;:/tmp/$ docker cp reducer.py &lt;namenode-container&gt;:/tmp/ Mapper (mapper.py): #!/usr/bin/env python3import sysfor line in sys.stdin:_, movie_id, rating, _ = line.strip().split('\\t')print(movie_id+'\\t'+rating) Explanation: For each line, output the movie ID as key and the rating as value. Reducer (reducer.py): #!/usr/bin/env python3import syscurrent_movie = Noneratings = []for line in sys.stdin:movie_id, rating = line.strip().split('\\t')if current_movie and movie_id != current_movie: print(current_movie+'\\t'+str(round(sum(ratings)/len(ratings), 2))) ratings = []current_movie = movie_idratings.append(float(rating))if current_movie:print(current_movie+'\\t'+str(round(sum(ratings)/len(ratings), 2))) Explanation: For each movie, compute and output the average of its ratings. Run the MapReduce JobNow that we have tested the map/reduce python script on the terminal, we can now run the scripts on the hadoop nodes. docker exec &lt;namenode-container&gt; \\ hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \\ -file /tmp/mapper.py -mapper /tmp/mapper.py \\ -file /tmp/reducer.py -reducer /tmp/reducer.py \\ -input /input/movieratings.csv \\ -output /output # 2025-05-05 22:48:57,076 WARN streaming.StreamJob... # ... # 2025-05-05 22:49:05,815 INFO mapreduce.Job: Job job... # 2025-05-05 22:49:05,816 INFO mapreduce.Job: map 0% reduce 0% # 2025-05-05 22:49:11,892 INFO mapreduce.Job: map 50% reduce 0% # 2025-05-05 22:49:12,901 INFO mapreduce.Job: map 100% reduce 0% # 2025-05-05 22:49:16,927 INFO mapreduce.Job: map 100% reduce 100% # 2025-05-05 22:49:16,936 INFO mapreduce.Job: Job .... completed successfully # 2025-05-05 22:49:17,032 INFO mapreduce.Job: Counters: 54 # ... # 2025-05-05 22:49:17,032 INFO streaming.StreamJob: Output directory: /outputUse a hive serverYou can query the data from a hive server that runs on the hadoop cluster nodes : Start the Hive server (from any cluster node): $ docker exec -it &lt;hive-server-container&gt; bash root@xxx:/opt/ beeline -u jdbc:hive2://localhost:10000 # SLF4J: Class path contains multiple SLF4J bindings. # SLF4J: Found binding in ... # SLF4J: Found binding in ... # SLF4J: See ... # SLF4J: Actual binding is of type ... # Connecting to jdbc:hive2://localhost:10000 # Connected to: Apache Hive (version 2.3.2) # ... # Beeline version 2.3.2 by Apache Hive 0: jdbc:hive2://localhost:10000&gt; Create an external table for results: beeline&gt; CREATE EXTERNAL TABLE movie_avg_rating ( movie_id STRING, avg_rating FLOAT ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t' LOCATION '/output'; Query results: SELECT * FROM movie_avg_rating ORDER BY avg_rating DESC LIMIT 4;+----------+-----------+---------+-----------+| user_id | movie_id | rating | datation |+----------+-----------+---------+-----------+| 196 | 242 | 3.0 | 881250949 || 186 | 302 | 3.0 | 891717742 || 305 | 451 | 3.0 | 886324817 || 6 | 86 | 3.0 | 883603013 |+----------+-----------+---------+-----------+Compare job durations as you increase the number of DataNodes.You can increase the number of nodes and confirm the following speed-ups. Nodes Example Time (s) Notes 1 120 Single DataNode 2 75 Parallel processing 3 55 Further speedup ConclusionThank you for your attention. Feel free to share this tutorial and to send your comments." }, { "title": "Hadoop : query data from a self-hosted hadoop cluster", "url": "/posts/hadoop-and-hive/", "categories": "microservcies", "tags": "apache, superset, postgresql, docker, solution architect, hive", "date": "2025-05-15 00:00:00 +0800", "snippet": "Hadoop is an affordable, reliable and scalable platform for big data storage and analysis ‚Äì it runs on commodity hardware and it is open source. Technically speaking, the Hadoop platform is the answer to the unevitable question we face one day or another as we live in a data age ‚Äì which is : how do we process tons of data efficiently ? It is not just about storage, but also, and even more, about implementing data processing models that can provide insights to decision makers in a competitive world ‚Äì where everything has to be fast and resilient.Kanmeugne‚Äôs Blog ‚Äì Hadoop : query data from a self-hosted hadoop clusterThere are many important concepts to know in order to understand the hadoop framework ‚Äì in this tutorial we will focus on 3 of them : Map/Reduce model : a programming model for data processing, inherently parallel, thus putting very large-scale data analysis into the hands of anyone with enough machines at their disposal. Map/Reduce program can be written in several popular languages ‚Äì Java, Python, Ruby etc. ‚Äì or wrapped using distributed tools, like Apache Hive, built on top of the hadoop platform. HDFS : Hadoop comes with a distributed filesystem called HDFS, which stands for Hadoop Distributed Filesystem. HDFS is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardware Apache YARN (Yet Another Resource Negotiator) is Hadoop‚Äôs cluster resource management system. YARN provides APIs for requesting and working with cluster resources, but these APIs are not typically used directly by user code. Instead, users write to higher-level APIs provided by distributed computing frameworks, which themselves are built on YARN and hide the resource management details from the userTo learn more about hadoop platform, the interested reader could have a look at this excellent book, published by Oreilly.How ToNow let‚Äôs jump to the hands on tutorial. I will mostly focus on high level operations ‚Äì data i/o and analysis ‚Äì for the interested users could easily find more specific tutorials on low-level operations. Here, we will rapidly set up a custom cluster using docker compose, add some data in the corresponding HDFS filesystem, and process the data using Hive.Set the self-hosted clusterThe full code for this tutorial is available from github, you just have to pull and run : Clone and deploy the Hadoop Docker setup: $ git clone https://github.com/kanmeugne/modern-data-architectures.git$ cd modern-data-architectures/handzon-hadoop-hive $ docker-compose up -d This launches namenodes, datanodes, and supporting services in containers. It also creates a hive server, to create and query data in a hdfs-compatible database. Check running containers: $ docker ps All Hadoop containers (namenode, datanode(s), etc.) should be listed. Check hdfs filesystem from inside the name node: $ docker exec &lt;namenode&gt; hdfs dfsadmin -report # this command lists all live DataNodes connected to the cluster.Configured Capacity: *** (*** GB)Present Capacity: *** (*** GB)DFS Remaining: *** (*** GB)DFS Used: *** (*** MB)DFS Used%: 0.01%Replicated Blocks: Under replicated blocks: 6 Blocks with corrupt replicas: 0 Missing blocks: 0 Missing blocks (with replication factor 1): 0 Low redundancy blocks with highest priority to recover: 6 Pending deletion blocks: 0Erasure Coded Block Groups: Low redundancy block groups: 0 Block groups with corrupt internal blocks: 0 Missing block groups: 0 Low redundancy blocks with highest priority to recover: 0 Pending deletion blocks: 0-------------------------------------------------Live datanodes (1):Name: *** (datanode.handzon-hadoop-hive_hadoop_network)Hostname: e20decb5140eDecommission Status : NormalConfigured Capacity: *** (*** GB)DFS Used: *** (*** MB)Non DFS Used: *** (*** GB)DFS Remaining: *** (*** GB)DFS Used%: 0.00%DFS Remaining%: 5.85%Configured Cache Capacity: 0 (0 B)Cache Used: 0 (0 B)Cache Remaining: 0 (0 B)Cache Used%: 100.00%Cache Remaining%: 0.00%Xceivers: 1Last contact: Fri May 09 20:23:16 UTC 2025Last Block Report: Fri May 09 20:17:40 UTC 2025Num of Blocks: 6 ... Add data in the clusterLet‚Äôs add some data in the distributed filesystem: Copy your CSV file into the namenode container: $ curl -L -o movieratings.csv https://files.grouplens.org/datasets/movielens/ml-100k/u.data$ docker cp movieratings.csv &lt;namenode&gt;:/tmp/ # on the docker host The dataset comes from GroupLens, a research lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specializing in recommender systems, online communities, mobile and ubiquitous technologies, digital libraries, and local geographic information systems. Load the CSV into an HDFS folder within the container: $ docker exec &lt;namenode&gt; hdfs dfs -mkdir -p /input$ docker exec &lt;namenode&gt; hdfs dfs -put /tmp/movieratings.csv /input/ # in the docker Explore your data with HiveUsing Hive you can explore data with SQL-like queries : Access the Hive service container $ docker exec -it &lt;hive-server&gt; bash # `&lt;hive-server&gt;` is the name of your hive server Create an external table from the HDFS file: # in the docker$ beeline -u jdbc:hive2://localhost:10000...Connecting to jdbc:hive2://localhost:10000Connected to: Apache Hive (version 2.3.2)Driver: Hive JDBC (version 2.3.2)Transaction isolation: TRANSACTION_REPEATABLE_READBeeline version 2.3.2 by Apache Hive... 0: jdbc:hive2://localhost:10000&gt;# This tells Hive to use the CSV at `/input` in HDFS as the data source.CREATE EXTERNAL TABLE IF NOT EXISTS movieratings ( user_id STRING, movie_id STRING, rating FLOAT, datation STRING) ROW FORMATDELIMITED FIELDS TERMINATED BY '\\t'STORED AS TEXTFILELOCATION '/input'; # hit enter # You should see this message after you hit `enter`No rows affected (1.629 seconds) Query the created table 0: hive2://localhost:10000&gt; select * from movieratings limit 4; # hit enter +----------+-----------+---------+-----------+| user_id | movie_id | rating | datation |+----------+-----------+---------+-----------+| 196 | 242 | 3.0 | 881250949 || 186 | 302 | 3.0 | 891717742 || 305 | 451 | 3.0 | 886324817 || 6 | 86 | 3.0 | 883603013 |+----------+-----------+---------+-----------+ Do some analytics using sql queries on the hive table # compute the average rating per movie0: jdbc:hive2://localhost:10000&gt; SELECT movie_id,AVG(rating) as ratingFROM movieratingsGROUP BY movie_idORDER BY LENGTH(movie_id), movie_idLIMIT 10; # results+-----------+---------------------+| movie_id | rating |+-----------+---------------------+| 1 | 3.8783185840707963 || 2 | 3.2061068702290076 || 3 | 3.033333333333333 || 4 | 3.550239234449761 || 5 | 3.302325581395349 || 6 | 3.576923076923077 || 7 | 3.798469387755102 || 8 | 3.9954337899543377 || 9 | 3.8963210702341136 || 10 | 3.831460674157303 |+-----------+---------------------+10 rows selected (2.909 seconds) 0: jdbc:hive2://localhost:10000&gt; !quit Voil√†! You can add nodes and compare execution timesFeel free to pull this repo and to send me your comments/remarks." }, { "title": "Apache Superset and Postgresql : connecting your database to a powerful data visualisation engine", "url": "/posts/postgresql-and-apache-superset/", "categories": "microservcies", "tags": "apache, superset, postgresql, docker, solution architect", "date": "2025-05-01 00:00:00 +0800", "snippet": "Data is only as valuable as the insights you can extract from it ‚Äî and in today‚Äôs world, those insights need to be fast, interactive, and visually compelling.Kanmeugne‚Äôs Blog : Apache Superset and Postgresql ‚Äî connecting your database to a powerful data visualisation engineApache Superset, a powerful open-source data visualization platform, is rapidly becoming the go-to tool for analysts and developers who want to turn raw data into actionable dashboards without wrestling with complex setup processes. Thanks to Docker and Docker Compose, spinning up a full-featured Superset environment takes just a few minutes, letting you focus on what matters: connecting to your data and building beautiful, shareable dashboards.Kanmeugne‚Äôs Blog : Apache Superset and Postgresql ‚Äî connecting your database to a powerful data visualisation engineIn this hands-on guide, you‚Äôll see how convenient it is to connect Superset to a PostgreSQL database using Docker Compose. Once you‚Äôre comfortable with Docker basics, Superset‚Äôs streamlined workflow makes dashboard creation not just possible, but enjoyable-even for complex data sources.I will assume you have installed Docker and Docker-compose on your computer ‚Äî follow this installation guide if you haven‚Äôt, and come back to the tutorial after.Build and run the application pull the application from the github repository$ git clone https://github.com/kanmeugne/modern-data-architectures.git$ cd modern-data-architecture/handzon-apache-superset create a .env with the required environment variables for the project :# postgres variablesPOSTGRES_USER=***POSTGRES_PASSWORD=***POSTGRES_DB=***POSTGRES_PORT=***# pgadmin variablesPGADMIN_DEFAULT_EMAIL=***PGADMIN_DEFAULT_PASSWORD=***PGADMIN_PORT=***# superset variableSUPERSET_SECRET_KEY=***SUPERSET_PORT=***SUPERSET_ADMIN_USERNAME=***SUPERSET_ADMIN_PASSWORD=***SUPERSET_ADMIN_EMAIL=***SUPERSET_ADMIN_FIRST_NAME=***SUPERSET_ADMIN_LAST_NAME=*** download the dataset and save the file into source_data (you need to do it before building the app) :handzon-apache-superset/source_data$ curl -L -o brazilian-ecommerce.zip \\ https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce handzon-apache-superset/source_data$ unzip brazilian-ecommerce.zip...handzon-apache-superset/source_data$ rm brazilian-ecommerce.zipData model of the Brazilian E-Commerce Public Dataset by Olist build the application with docker compose from the project folder :handzon-apache-superset$ docker compose up -d...The build process might be long at first run, so be patient‚Ä¶Database walkthroughWhen everything is up, use your favorite browser and do the following checkups : check the database content by opening the pgadmin web endpoint in your browser : http://localhost:&lt;PGADMIN_PORT&gt;. You will have to log in pgadmin with the username and the password that you have defined in the .env file.# pgadmin variablesPGADMIN_DEFAULT_EMAIL=***PGADMIN_DEFAULT_PASSWORD=***PGADMIN_PORT=***PGAdmin Login Page : use the credentials defined in .env navigate in your database by setting a connection with the proper variables (the server address is the name of corresponding service container : postgis)# postgres variablesPOSTGRES_USER=***POSTGRES_PASSWORD=***POSTGRES_DB=***POSTGRES_PORT=***PGAdmin Connexion + Navigation into your sql tablesCreate analytics within SupersetTo be able to create analytics, you should at least : set a database connexion create datasets create charts and add them to dashboardsCreate a database connexionFollow these steps in order to create a connexion to your postgresql database : open the superset endpoint in your browser : http://localhost:&lt;SUPERSET_PORT&gt; and use the following credentials to sign in : SUPERSET_PORT=***SUPERSET_ADMIN_USERNAME=***SUPERSET_ADMIN_PASSWORD=*** login into Superset when signed in, go to (1) + &gt; (2) Data &gt; (3) Connect database to configure a new database connexionadd connexion to the database - select data source click on the Postgresql button since we are using a Postgresql Databaseadd connexion to the database - select database type use the postgresql credentials from the .env and click Connexion, then Finish buttons.add connexion to the database - set credential and save the connexionWithin the tool, you can now query data from the database and build the analytics upon it.Create a datasetDatasets can be created either directly from sql table or from sql queries. In this tutorial, we are going to create one from a sql query : Go to the Menu (1) SQL&gt;SQL Lab, to open the sql dataset creation wizard. Use the (2) DATABASE field to select the database connexion you just created Use (3) SCHEMA field to pick the right schema.create the query to be used as the dataset In the right panel, copy the following sql code to collect relevant data about orders, products and sellers SELECT oi.order_id, oi.product_id, tr.product_category_name_english as product_name, oi.price, oc.customer_cityfrom olist_order_items_dataset oi inner join olist_orders_dataset oo on oo.order_id = oi.order_id inner join olist_customers_dataset oc on oo.customer_id = oc.customer_id inner join olist_products_dataset op on oi.product_id = op.product_id left join product_category_name_translation tr on op.product_category_name = tr.product_category_name save the dataset as orders, products, sellersNow that we have created an extended dataset on orders and products, we can edit charts and dashboards to explore it.Create chartsLet‚Äôs create 3 charts that we are going to add to a dashboard later.$1^{st}$ chart : total sales per city on the dataset tab, click on orders, products, sellers drag price attribute from the left panel and drop it in the metrics cell - confirm SUM(price) as the agregation operation. drag customer_city from the left panel to the Dimensions cell. You should see the following chart (see screenshot). Save it as total sales per citycreate a chart from the dataset$2^{nd}$ chart : number of different products per city on the dataset tab, click on orders, products, sellers use product_id as the metric (confirm COUNT_DISTINCT(product_id) as the agregation operation), and product_name as the dimension. You should see this chart (save it as number of different products per city)create a second chart from the dataset$3^{rd}$ chart : top ten sales on the dataset tab, click on orders, products, sellers use product_id as the metric (confirm COUNT_DISTINCT(product_id) as the agregation operation), and product_name as the dimension. use the ROW LIMIT option to limit the number of items to 10. You should see this chart (save it as top ten sales)create a third chart from the datasetIt is now possible to agregate charts into a dashboard to have an overview of your dataCreate a dashboardDashboard creation is quite simple : on the dashboard tab, add a new dashboardcreate a new dashboard check on the right pane to see the charts you can use to build your dashboard (you should see the charts you have created above)explore charts on the right panel drag all your charts from the right pane and drop them anywhere on the dashboard canvadrag and drop charts into the dashboard save the dashboard as Product Sales View.set the dashboard title and saveYou should now see Product Sales View under the dashboard tab. Interested readers could check the Apache Superset website to see how to attach CSS template to get more compeling visuals.ConclusionI hope this tutorial will be helpful for those who want to play with Apache SuperSet and PostgreSQL. Feel free to send me your comments and remarks." }, { "title": "Setting Up Your python Environment (II)", "url": "/posts/setting-up-virtual-environments-in-python/", "categories": "software development", "tags": "python, jupyter, ipython, programming", "date": "2022-05-04 00:00:00 +0800", "snippet": "Dans un article pr√©c√©dent, j‚Äôexpliquais en 3 √©tapes comment mettre en place un environnement de programmation en Python. Il existe plusieurs options d‚Äôinstallation en r√©alit√© (anaconda, winpython, etc.) mais j‚Äôai privil√©gi√© la plus bas niveau ‚è¨.La proc√©dure que j‚Äôai pr√©sent√©e suppose l‚Äôutilisation d‚Äôun syst√®me Linux. J‚Äôai insist√© sur le fait qu‚Äôil ne s‚Äôagissait pas d‚Äôune contrainte ‚Äì bien au contraire ‚Äì et ce pour au moins 2 raisons : Premi√®rement, Linux est tr√®s populaire aupr√®s des d√©veloppeurs - le d√©butant pourra donc automatiquement profiter d‚Äôune importante communaut√© d‚Äôentraide üíÉ. Deuxi√®mement, Windows ‚Äì qui est de loin l‚ÄôOS le plus populaire tout court ‚Äì propose des sous-syst√®mes Linux natifs dans ses derni√®res versions. Il est donc tr√®s facile de travailler sous linux aujourd‚Äôhui (encore plus que par le pass√©) quelque soit la version r√©cente de Windows install√©e sur sa machine (pour les utilisateurs de MacOs, l‚Äôexp√©rience montre que les proc√©dures d‚Äôinstallation ‚Äì au moins √† partir d‚Äôun terminal ‚Äì sont quasi similaires).Photo by Ralston Smith on Unsplash.Dans cet article, nous allons un peu plus loin dans l‚Äôorganisation de l‚Äôespace de travail du developpeur python avec la mise en place d‚Äôenvironnments virtuels.Pourquoi utiliser un environnement virtuel ?Le monde des d√©veloppeurs est un monde complexe, plein de contrari√©t√©s et d‚Äô√©preuves.Il peut arriver par exemple : que vous ayez besoin d‚Äôune version bien pr√©cise de l‚Äôinterpr√©teur python ‚Äì diff√©rente de la version install√©e sur votre syst√®me ‚Äì parceque la lib X que vous convoitez ne marche qu‚Äôavec cette version-l√† ! que, bien que vous utilisiez la version la plus r√©cente de la lib X dans votre code Y, vous ayez besoin d‚Äôune version plus ancienne de la lib X pour qu‚Äôun autre bout de code Z ‚Äì que vous avez eu tant de mal √† d√©velopper ‚Äì continue de fonctionner sur votre machine ! que vous ayez envie ‚Äì et c‚Äôest votre droit le plus absolu ‚Äì d‚Äôisoler vos projets python pour avoir une bonne vision des d√©pendances et des lib utilis√©es.Pour faire simple, vous pouvez √™tre confront√© √† deux cas de figure : cohabitation : vous avez besoin de faire cohabiter plusieurs versions d‚Äôinterpreteurs python ou de lib python isolement : vous voulez isoler vos projets pour avoir une bonne visibilit√© sur les lib et les d√©pendances n√©cessaires pour votre projet.Si vous vous retrouvez dans l‚Äôun ces deux cas de figure, vous avez certainement besoin d‚Äôutiliser un environnement virtuel.Que faut-il installer pour utiliser un environnement virtuel ?Nous allons consid√©rer que nous sommes dans les configurations de l‚Äôarticle cit√© √† l‚Äôintroduction ‚Äì si vous ne l‚Äôavez pas lu, faites-le et revenez vite üòº.Commencez par installer virtualenv et virtualenvwrapper qui sont des lib python qui permettent : de cr√©er un environnement de dev isol√© du reste du syst√®me (virtualenv) de g√©rer les environnements virtuel depuis le terminal (virtualenvwrapper)pip install virtualenv virtualenvwrappervirtualenvwrapper cr√©e un programme ‚Äì virtualenvwrapper.sh ‚Äì qui doit s‚Äôex√©cuter √† chaque d√©but session du terminal pour d√©finir les commandes permettant de g√©rer les environnements virtuels. Assurez-vous de bien le localiser et de l‚Äôex√©cuter dans votre ~/.bashrc pour que les commandes soient cr√©√©es automatiquement √† chaque session.Pensez aussi √† d√©clarer le dossier dans lequel les environnements virtuels seront cr√©√©s WORKON_DIR.Ci-dessous, un exemple de configuration.# ~/.bashrc (ou ~/.zshrc)# interpr√©teur par defautexport VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3 # les environnements virtuels sont cr√©es iciexport WORKON_HOME=~/.virtualenvs ## generer les commandes pour g√©rer les environnements virtuelssource ~/.local/bin/virtualenvwrapper.sh# pour utiliser l'environnement virtuel d√®s sa cr√©ationexport PIP_RESPECT_VIRTUALENV=true üíÅ Pour plus d‚Äôoptions de configuration, bien vouloir consulter la documentation officielle.Voil√†, vous √™tes pr√™ts √† tester les environnements virtuels.Comment utiliser un environnement virtuel ? ‚ö† Le tutoriel est bas√© sur virtualenv 20.2.2!$ pip show virtualenv Name: virtualenvVersion: 20.2.2Summary: Virtual python Environment builder... Premi√®rement, il faut en cr√©er un‚Ä¶ Et pour cela, vous devez utiliser la commande mkvirtualenv. Nous allons utiliser mkvirtualenv pour cr√©er un environnement virtuel que nous allons appeler myenv.$ mkvirtualenv --python 3 myenvcreated virtual environment CPython3.8.10.final.0-64 in 200ms ...virtualenvwrapper.user_scripts creating ~/.virtualenvs/myenv/bin/predeactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myenv/bin/postdeactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myenv/bin/preactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myenv/bin/postactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myenv/bin/get_env_details(myenv) $ Vous devriez obtenir l‚Äô√©quivalent des logs ci-dessus. Remarquez que le prompt a l√©g√®rement chang√© (si tout s‚Äôest bien pass√©). Vous avez maintenant (myenv) avant l‚Äôinvite (cf. ligne 10).√Ä partir de maintenant, on travaille dans un espace virtuel ‚Äì toutes les installations de lib se feront dans cet espace uniquement, et non sur l‚Äôensemble du syst√®me.On peut v√©rifier que l‚Äôespace nouvellement cr√©√© est quasi vierge et que tr√®s peu de lib sont pr√©-install√©es (juste de quoi installer d‚Äôautres lib üòâ)(myenv) $ pip listPackage Version---------- -------pip 22.1setuptools 46.1.3wheel 0.34.2Installons le prompt ipython dans notre environnement virtuel, histoire de le remplir un peu‚Ä¶ Rien de tr√®s compliqu√©, il s‚Äôagit exactement des m√™mes commandes que d‚Äôhabitude ‚Äì pip install ipython ‚Äì la seule diff√©rence √©tant que l‚Äôinstallation se fait uniquement dans l‚Äôenvironnement virtuel.(myenv) $ pip install ipythonCollecting ipython Using cached ipython-8.3.0-py3-none-any.whl (750 kB)Collecting jedi&gt;=0.16 Using cached jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)Collecting traitlets&gt;=5 Using cached traitlets-5.2.1.post0-py3-none-any.whl (106 kB) ...Successfully installed asttokens-2.0.5 ...On peut constater que l‚Äôenvironnement est un peu plus charg√© ‚Äì ce qui est tout a fait normal car ipython a √©t√© install√©, avec plusieurs autres d√©pendances (n√©cessaires au fonctionnement de ipython).(myenv) $ pip listPackage Version----------------- -----------asttokens 2.0.5backcall 0.2.0decorator 5.1.1executing 0.8.3ipython 8.3.0jedi 0.18.1matplotlib-inline 0.1.3parso 0.8.3pexpect 4.8.0pickleshare 0.7.5pip 22.1prompt-toolkit 3.0.29ptyprocess 0.7.0pure-eval 0.2.2Pygments 2.12.0setuptools 46.1.3six 1.16.0stack-data 0.2.0traitlets 5.2.1.post0wcwidth 0.2.5wheel 0.34.2Voil√†! On peut maintenant utiliser ipython depuis notre environnement virtuel myenv.(myenv) ipythonPython 3.8.10 (default, Mar 15 2022, 12:22:08) Type 'copyright', 'credits' or 'license' for more informationIPython 8.3.0 -- An enhanced Interactive Python. Type '?' for help.In [1]: print(\"coucou\")coucouIn [2]: Vous pouvez sortir de l‚Äôenvironnement virtuel ‚Äì commande deactivate ‚Äì et constater que vous n‚Äôavez plus acc√®s √† ipython (sauf si vous l‚Äôaviez sur tout le syst√®me avant bien s√ªr. Si c‚Äôest le cas, d√©sinstallez-le avant de suivre ce tutoriel).(myenv) $ deactivate$ ipythonbash: command not found: ipythonComment sauvegarder mon environnement virtuel ?Un des inter√™ts des environnements virtuels c‚Äôest d‚Äôavoir une vision claire des d√©pendances n√©cessaires pour son code python. On peut ainsi reproduire son environnement de travail en toute s√©r√©nit√© et n‚Äôimporte quand.Pour sauvegarder et cloner son environnement virtuel, on peut proc√©der de la mani√®re suivante : je me connecte √† l‚Äôenvironnement que je souhaite sauvegarder :$ workon myenv(myenv) $ je sauvegarde l‚Äô√©tat de l‚Äôenvironnement dans un fichier texte, gr√¢ce notemment √† la commande pip freeze. A la diff√©rence de pip list, la commande pip freeze affiche les d√©pendances dans un format directement exploitable pour l‚Äôinstallation.(myenv) $ pip freezeasttokens==2.0.5backcall==0.2.0decorator==5.1.1executing==0.8.3ipython==8.3.0jedi==0.18.1matplotlib-inline==0.1.3parso==0.8.3pexpect==4.8.0pickleshare==0.7.5prompt-toolkit==3.0.29ptyprocess==0.7.0pure-eval==0.2.2Pygments==2.12.0six==1.16.0stack-data==0.2.0traitlets==5.2.1.post0wcwidth==0.2.5(myenv) $ pip freeze &gt; requirements.txt(myenv) $ ls *.txtrequirements.txt enfin, je clone mon environnement gr√¢ce au fichier de sauvegarde requirements.txt (pour l‚Äôexemple, on supprime myenv au pr√©alable, avec la commande rmvirtualenv)(myenv) $ deactivate$ rmvirtualenv myenvRemoving myenv...$ mkvirtualenv --python 3 -r requirements.txt myclonenvcreated virtual environment CPython3.8.10.final.0-64 in 112ms...virtualenvwrapper.user_scripts creating ~/.virtualenvs/myclonenv/bin/predeactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myclonenv/bin/postdeactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myclonenv/bin/preactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myclonenv/bin/postactivatevirtualenvwrapper.user_scripts creating ~/.virtualenvs/myclonenv/bin/get_env_detailsCollecting asttokens==2.0.5 Using cached asttokens-2.0.5-py2.py3-none-any.whl (20 kB)Collecting backcall==0.2.0 Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)...Installing collected packages: six, asttokens, ...$ (myclonenv) pip listPackage Version----------------- -----------asttokens 2.0.5backcall 0.2.0decorator 5.1.1executing 0.8.3ipython 8.3.0jedi 0.18.1matplotlib-inline 0.1.3parso 0.8.3pexpect 4.8.0pickleshare 0.7.5pip 22.1.1prompt-toolkit 3.0.29ptyprocess 0.7.0pure-eval 0.2.2Pygments 2.12.0setuptools 46.1.3six 1.16.0stack-data 0.2.0traitlets 5.2.1.post0wcwidth 0.2.5wheel 0.34.2Votre environnement est parfaitement clon√© ! Et vous voil√† initi√© √† l‚Äôutilisation des environnements virtuels en python. Tr√®s utile : l‚Äôaide sur la commande mkvirtualenv ‚Äì mkvirtualenv --help les documentations officielles de virtualenv et virtualenvwrapper pour plus d‚Äôoptions. R√©f√©rences Anaconda.com Winpython.github.io Virtualenv.pypa.io Virtualenvwrapper.readthedocs.io Ipython.org Kanmeugne‚Äôs Blog : Setting Up Your Python Environment" }, { "title": "Setting Up Your Python Environment (I)", "url": "/posts/setting-up-your-python-environment/", "categories": "software development", "tags": "python, jupyter, ipython, programming", "date": "2022-05-03 00:00:00 +0800", "snippet": "I have been talking python with different kind of programmers ‚Äì from beginners to experienced programmers ‚Äì and there is this little issue that, surprisingly, does not have a straightforward answer : what do you need to install to start programming in python ?This post is dedicated to this little issue and I will try to explain what ‚Äì in my opinion ‚Äì is the easiest path from nothing‚Ä¶ to‚Ä¶ a decent python programming environment.Photo by Amr Taha‚Ñ¢ on Unsplash.Our journey will have several stages ‚Äì and you will have to do some installation homework in order to travel from one stage to another.At the first stage, you will have to make sure that you are working on the right Operating System and with the right terminal ‚Äì meaning, compatible with the instructions of this post. !!! Spoiler Alert !!! We will go for a linux OS since it is very popular among programmers and easy to set up ‚Äì don‚Äôt shoot.At the second stage, you should have installed python 3 on your computer ‚Äì we will see that, once installed, you technically have a working python programming environment. We will show off two programming modes at this stage : an interactive mode ‚Äì where you can type commands and see the result in an interactive prompt ‚Äì a script mode ‚Äì where you can run full python scripts using the python interpreter from the terminal.At the third stage, we will enrich our programming environment with high-level python prompts ‚Äì like ipython and jupyter ‚Äì and advanced Integrated Development Environments (IDEs) ‚Äì like vscode. High-level prompts give more context to programmers and are clearly a most-have if you want to improve your interactive programming experience. IDEs, as you might expect, improve the script programming experience with embedded tools for : script execution, coding style, code highlighting, testing, etc.Now, let‚Äôs begin‚Ä¶1. The OS : where everything startsPhoto by Gabriel Heinzer on UnsplashI will assume that you are working on a Linux machine. The first reason I am confident with this assumption is that Linux is a very popular OS for developers (beginners and experienced ones) and Microsoft (which is the most popular OS among normal human being) provides a descent linux subsystem which is an Ubuntu distribution by default. I am thus pretty sure that if the reader (this is you) is a windows user (which is highly possible), he/she will be able to set up a Linux machine, even on his/her windows computer, with little effort ‚Äì the interested reader could check this article to understand how to set it up.The second reason I am confident is that, if you are a Mac user (which is highly possible), most of the setup and commands I will show in this post will work on your OS with very little or no change at all. Anyway, for the sake of straightforwardness, I will assume a linux OS ‚Äì I will focus on MacOs in another post.2. The Python interpreter : the mandatory installPhoto by Alex Chumak on Unsplash Python is actually an interpreter, which means that, unlike a compiler, a python code is parsed and executed dynamically by a special program which is : the Python Interpreter.If you have a linux OS setup, it is highly possible that you already have a python shipped with your system. But you need to install the right version and make sure to be able to track it down ‚Äì as you might expect, the interpreter parsing and executing behaviour depends on its version. So how do you install the right python interpreter ? Since you are working on a full linux system (as we have assumed above), you can do the following steps : Check if a python3.X.X is already installed. You can type the following command on your terminal : $ python --version If the result of this command looks like python X.Y.Z where X&lt;3 or if the command fails, you should probably install python 3.X.X. It is highly recommended since most of the python modules and tools provided by the community will not be maintained for older versions. So how do you install python 3 ? You need to install python 3, and the exact how depends on your linux distribution. For Ubuntu distributions (WSL runs Ubuntu by default), the following instructions should be sufficient (for python 3.8, but you can pick any 3.X version you want). $ sudo apt-get update $ sudo apt-get install python3.8 Anyway, I encourage üí™ you to read this post and get the right instructions for your linux distribution. Come back here when you are done with the installation. Now, you should have the right version installed and technically, you are ready to start programming in Python ‚Äì you are ready to experience two different programming modes : the interactive mode and the script mode.Interactive ModeIn the interactive mode, you will be able to launch the default prompt, start typing python commands and see the results interactively by hiting the ‚èé key.To experience it now, open your linux terminal and do the following steps : Launch the python prompt $ python The above command opens the default prompt which allows you type any valid python command. For example, type the following : &gt;&gt;&gt; func = lambda x : x+1 # hit the enter key to create this lambda function &gt;&gt;&gt; print(func(6)) # hit the enter key and you should see the result below 6 Add verbosity with the following : &gt;&gt;&gt; print(\"the result of func(5) is: \", func(5)) the result of func(5) is: 6 The animation below looks almost like what you should get if you don‚Äôt mistype.Fig. Running python commands interactively using the default python promptScript ModeAs you might have guessed, in the script mode, your commands should be saved in a text file ‚Äì that will be your python script. To execute it, just open your terminal and hit : python &lt;yourpythonscriptpath&gt;.For example, let‚Äôs copy the previous section‚Äôs commands in a file and try them in a script mode : Open an empty text file called test.py with your favorite editor and type in the following (make sure to save the file in your current workspace üòã) : #!/usr/bin/python3 func = lambda x: x+1 print(\"the result of func(5) is: \", func(5)) Save your file, and type the command below in a linux terminal $ python test.py the result of func(5) is: 6 or $ chmod +x test.py $ ./test.py the result of func(5) is: 6 This is it for the script mode!! All you need to do, basically, is to save your commands in a text file, and then, run it in a terminal with the appropriate python interpreter. In the next section will see how you can enrich your programming experience with advanced prompts and code editors üëå.3. Enriching your programming environmentAdvanced promptsYou can enrich your environment with advanced prompts. I am not going to review all the available prompts in this post, but there are two of them that I would like to show off.IPythonipython is an advanced prompt that you can install on your computer as a python package. All you have to do is the following in a linux terminal :$ pip install ipython --userCompared to the default python prompt, ipython is a more colorful prompt and full of helpers that allow for example to : navigate in the filesystem without exiting the prompt highlight your code (cf. animation) auto-complete commands see the available attributes and methods of an object display the commands history (cf. animation below) display the execution time of a command etc.Fig. IPython in actionJupyteripython is used as the core for even more advanced prompts like the famous web-based prompt : Jupyter Notebook.The Jupyter Notebook is the original web application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience.As for ipython, jupyter notebook is installable as a python package :$ pip install jupyterIf the above üëÜ command does not work, please go the official installation website to get the most updated procedure. Once installed, run a notebook just by typing the following command on your terminal :jupyter notebookCheck the animation below üëá to see jupyter in actionFig. Jupyter notebook in actionIntegrated Development Environments (IDEs)Python code editors are designed for developers who want their best development tools perfectly integrated. There are editors for every type of programmers ‚Äì the best ones being those you better flow with. Here is a non-exhaustive list of features one could be expecting for, while looking for the perfect IDE : a step-by-step debugger code navigation tool syntax highlighting auto completion/importation diff tools to see how the code changes between files unit/integration test tools integration etc.Below, a list of IDEs I have already seen in action (‚ö† my pick is completely innocent üòÅ) : Visual Studio Code (or vscode) is a lightweight but powerful source code editor which runs on your desktop and is available for Windows, macOS and Linux. It comes with built-in support for JavaScript, TypeScript and Node.js and has a rich ecosystem of extensions for other languages (such as C++, C#, Java, Python, PHP, Go) and runtimes (such as .NET and Unity) Sublime Text is a shareware cross-platform source code editor. It natively supports many programming languages and markup languages. Users can expand its functionality with plugins, typically community-built and maintained under free-software licenses. To facilitate plugins, Sublime Text features a Python API. PyCharm is an integrated development environment used in computer programming, specifically for the Python programming language. It is developed by the Czech company JetBrains (formerly known as IntelliJ). It provides code analysis, a graphical debugger, an integrated unit tester, integration with version control systems, and supports web development with Django as well as data science with Anaconda. If you want an extensive review, please check this well-documented article on python IDEs.4. References Geek4Geeks.com Python.org docs.python-guide.org/starting/install3/linux/ Guru99.com/python-ide-code-editor.html Jupyter.org Ipython.org Code.visualstudio.com Sublimetext.com JetBrains.com/PyCharm" }, { "title": "Introduction au TDD (II) : le cycle vertueux", "url": "/posts/tdd-cycle-vertueux/", "categories": "software development", "tags": "cmake, c++, tdd", "date": "2021-10-29 00:00:00 +0800", "snippet": "Dans la premi√®re partie de cet exercice, je me suis concentr√© sur la mise en place de l‚Äôespace de travail et la validation du test zero (qui est tout simplement la compilation). On va se concentrer maintenant sur l‚Äôimpl√©mentation des fonctionnalit√©s de la lib t√©moin. On verra en quoi l‚Äôapproche TDD permet d‚Äôenvisager sereinement l‚Äô√©volution du code et le refactoring.Photo by Liam Tucker on UnsplashLe mindsetPour rappel, le developpeur TDD respecte le cycle suivant : √âcrire des petits tests S‚Äôassurer que les tests √©chouent dans un premier temps √âcrire le code qui permet passer le test S‚Äôassurer que le test passe Nettoyer (ou r√©factorer) le code S‚Äôassurer que le test passe toujours Retourner √† l‚Äô√©tape 1.La particularit√© de cette approche est qu‚Äôon d√©finit les tests en premier lieu ‚Äî la production de code a pour objectif de les valider.Le premier testPour commencer la production de notre lib toolset, il faut donc pr√©lablement d√©finir un test qui est sens√© √©chouer dans l‚Äô√©tat actuel du code. Commen√ßons par le test ci-dessous :class ParserTest : public Test{};TEST(ParserTest, Parser_LowerSingleLetter){ std::string output = \"\"; std::string input = \"L\"; std::string expected = \"l\"; MyParser parser; parser.convertToLowerCase(input, output);\tASSERT_EQ(output, \"l\");}// ... Traduction en langage naturel : La fonction convertToLowerCase du parser convertit la lettre ‚ÄúL‚Äù majuscule en ‚Äúl‚Äù minusculeQuelques mots clefs dans cette d√©finition n√©cessitent une petite explication : TEST est la macro googletest qui permet de d√©finir un test unitaire. ASSERT_EQ est une autre MACRO qui permet de tester si 2 variables ont la m√™me valeur (voir la documentation de googletest pour plus d‚Äôinfos sur les macros disponibles). La d√©claration de la classe ParserTest (d√©riv√©e de testing::Test) permet de regrouper les tests par th√©matique ‚Äî comme on le verra plus bas, ce m√©canisme permet aussi de d√©finir des fixtures. Parser_LowerSingleLetter : est le nom du test. Tr√®s utile quand il faudra lire les r√©sultats des tests sur la console.Le test d√©fini ci-dessus est simple (une assertion) avec un objectif exprimable en langage naturel : le parseur doit transformer la lettre L (majuscule) en la lettre l (minuscule). Produisons maintenant le code qui permet de le valider.La premi√®re validationPour l‚Äôinstant le test √©choue √† cause d‚Äôun probl√®me de compilation puisque la classe MyParser n‚Äôest pas vraiment d√©finie. En √©crivant le strict minimum dans MyParser.h pour que la compilation fonctionne,#include \"MyParser.h\"//MyParser::convertToLowerCasevoid MyParser::convertToLowerCase(const std::string &amp;input, std::string &amp;output){ output = \"\";}//MyParser::MyParserMyParser::MyParser(){}//MyParser::~MyParserMyParser::~MyParser(){}on obtient un message d‚Äôerreur plus conventionnel :[==========] Running 1 test from 1 test suite.[----------] Global test environment set-up.[----------] 1 test from ParserTest[ RUN ] ParserTest.Parser_LowerSingleLetter/.../tests/src/main.cpp:15: FailureExpected equality of these values: output Which is: \"\" \"l\"[ FAILED ] ParserTest.Parser_LowerSingleLetter (0 ms)[----------] 1 test from ParserTest (0 ms total)[----------] Global test environment tear-down[==========] 1 test from 1 test suite ran. (0 ms total)[ PASSED ] 0 tests.[ FAILED ] 1 test, listed below:[ FAILED ] ParserTest.Parser_LowerSingleLetter 1 FAILED TESTEn d‚Äôautre termes, le test Parser_LowerSingleLetter √©choue car la valeur obtenue par le parser ‚Äî la chaine de caract√®re vide ‚Äî ne correspond pas √† la valeur attendue ‚Äî ‚Äúl‚Äù.Pour que le test soit valid√©, il faut produire une impl√©mentation correcte de la fonction MyParser::convertToLowerCase dans MyParser.cpp. Pour cela, disons que la fonction parcourt la chaine de caract√®res, transforme en minuscules tous les caract√®res et les rajoute dans la variable de sortie. Ce qui nous donne l‚Äôimpl√©mentation suivante ://MyParser::convertToLowerCasevoid MyParser::convertToLowerCase(const std::string &amp;input, std::string &amp;output){ output = \"\"; for (auto c : input) output.push_back(tolower(c));}Avec cette impl√©mentation, le test est OK. On a produit le code qui valide notre premier test unitaire ‚Äî je laisse au lecteur le soin de rajouter d‚Äôautres tests sur cette premi√®re fonction pour √©prouver le code s‚Äôil le souhaite.[==========] Running 1 test from 1 test suite.[----------] Global test environment set-up.[----------] 1 test from ParserTest[ RUN ] ParserTest.Parser_LowerSingleLetter[ OK ] ParserTest.Parser_LowerSingleLetter (0 ms)[----------] 1 test from ParserTest (0 ms total)[----------] Global test environment tear-down[==========] 1 test from 1 test suite ran. (0 ms total)[ PASSED ] 1 test. La production de code valide le test, on peut avancer dans le d√©veloppement.Red, Green, RefactorEcrivons notre deuxi√®me test pour la deuxi√®me fonction :TEST(ParserTest, Parser_UpperSingleLetter){ std::string output = \"\"; std::string input = \"l\"; std::string expected = \"L\"; MyParser parser; parser.convertToUpperCase(input, output);\tASSERT_EQ(output, \"L\");}Comme le premier, le deuxi√®me test √©choue puisque la fonction MyParser::convertToUpperCase n‚Äôest pas d√©finie. Effectuons les modifications de code qui permettent de valider le test.Tout d‚Äôabord, la mise √† jour des d√©finitions dans le fichier ./toolset/include/MyParser.h,class MyParser{public: MyParser(); ~MyParser(); void convertToLowerCase(const std::string &amp;, std::string &amp;); void convertToUpperCase(const std::string &amp;, std::string &amp;);};puis l‚Äôimpl√©mentation de la fonction convertToUpperCase dans le fichier ./toolset/src/MyParser.cpp,//MyParser::convertToUpperCasevoid MyParser::convertToUpperCase(const std::string &amp;input, std::string &amp;output){ output = \"\"; for (auto c : input) output.push_back(toupper(c));}L‚Äôex√©cution des tests renvoie maintenant le r√©sultat suivant :[==========] Running 2 tests from 1 test suite.[----------] Global test environment set-up.[----------] 2 tests from ParserTest[ RUN ] ParserTest.Parser_LowerSingleLetter[ OK ] ParserTest.Parser_LowerSingleLetter (0 ms)[ RUN ] ParserTest.Parser_UpperSingleLetter[ OK ] ParserTest.Parser_UpperSingleLetter (0 ms)[----------] 2 tests from ParserTest (0 ms total)[----------] Global test environment tear-down[==========] 2 tests from 1 test suite ran. (0 ms total)[ PASSED ] 2 tests.On voit que le premier test reste valide ‚Äî ce qui signifie qu‚Äôil n‚Äôy a pas eu de regression ‚Äî et que le deuxi√®me test est √©galement OK. La logique de production est toujours la m√™me et peut se r√©sumer en une formule synth√©tique : Red, Green, Refactor : Red (le test √©choue d‚Äôabord), Green (le test passe apr√®s une modification du code, tous les tests pr√©c√©dents doivent toujours √™tre valides) Refactor (on restructure le code pour une coh√©rence d‚Äôensemble et on rev√©rifie que tous les tests passent toujours)On remarque le cycle vertueux qui oblige √† avancer lentement mais surement en faisant le moins de d√©g√¢ts possible.Cas d‚Äôusage de RefactoringL‚Äôapproche TDD se pr√™te √©galement bien aux t√¢ches de refactoring pures. Dans ces cas, on profite des tests d√©j√† d√©finis pour controler la qualit√© du code.Pour notre exemple, essayons un refactoring en deux √©tapes : Cr√©ation d‚Äôun namespace utils, qui contiendra les d√©finitions de la classe MyParser. Ajout d‚Äôune fonction dans la biblioth√®que qui renvoie une instance unique de MyParserRefactoring 1 : ajouter un namespacePour la premi√®re √©tape, modifions tout d‚Äôabord les tests qui doivent valider le code. La logique des tests n‚Äôest pas modifi√©e ‚Äî ce qui serait une faute grave ‚Äî juste l‚Äôinitialisation du parser.TEST(ParserTest, Parser_LowerSingleLetter){ std::string output = \"\"; std::string input = \"L\"; std::string expected = \"l\"; utils::MyParser parser; // namespace utils parser.convertToLowerCase(input, output);\tASSERT_EQ(output, \"l\");}TEST(ParserTest, Parser_UpperSingleLetter){ std::string output = \"\"; std::string input = \"l\"; std::string expected = \"L\"; utils::MyParser parser; // namespace utils parser.convertToUpperCase(input, output);\tASSERT_EQ(output, \"L\");}Naturellement ‚Äî et heureusement ‚Äî ces tests √©chouent dans un premier temps puisque MyParser.h n‚Äôest pas d√©fini dans le bon namespace. Les modifications suivantes vont permettre de les valider.D‚Äôabord le fichier ./toolset/include/MyParser.h,#ifndef MYPARSER_H#include &lt;string&gt;namespace utils{ class MyParser { public: MyParser(); ~MyParser(); void convertToLowerCase(const std::string &amp;, std::string &amp;); void convertToUpperCase(const std::string &amp;, std::string &amp;); };} // namespace utils#endif // MYPARSER_HPuis le fichier ./toolset/src/MyParser.cpp, dans lequel il suffira de rajouter la ligne ci-dessous :using namespace utils;Les tests refonctionnent! Refactoring r√©ussi en toute s√©r√©nit√©.Maintenant voyons pour le deuxi√®me refactoring.Refactoring 2: utiliser une r√©f√©rence uniquePour la deuxi√®me √©tape du refactoring, l‚Äôid√©e est de rajouter une fonction ‚Äî utils::getParser ‚Äî qui renvoie une instance unique de MyParser. On testera cette fonction en utilisant une nouvelle classe dans le fichier ./tests/main.cpp ://Les fixtures sont des attributs publiques des classes Testclass UniqueParserTest : public Test{public: utils::MyParser_t &amp;_parser; UniqueParserTest():_parser(utils::getParser()) {}};La classe UniqueParserTest d√©finit une fixture UniqueParserTest::_parser qui est initialis√©e dans UniqueParserTest::UniqueParserTest().Les tests UniqueParserTest vont permettre de valider, d‚Äôune part, que la fonction utils::getParseur retoune toujours la m√™me instance, et d‚Äôautre part, que toutes les fonctionnalit√©s du parseur sont bien valid√©es par cette instance.On d√©finit les nouveaux tests suivants ‚Äî on notera l‚Äôutilisation de la macro TEST_F √† la place de TEST, ce qui permet exploiter les fixtures dans le test :TEST_F(UniqueParserTest, Parser_UniqueParserIsUnique){ utils::MyParser_t&amp; p = utils::getParser(); ASSERT_EQ(std::addressof(p), std::addressof(_parser));}TEST_F(UniqueParserTest, Parser_UniqueParserLowerSingleLetter){ std::string output = \"\"; std::string input = \"L\"; std::string expected = \"l\"; _parser-&gt;convertToLowerCase(input, output); ASSERT_EQ(output, \"l\");}TEST_F(UniqueParserTest, Parser_UniqueParserUpperSingleLetter){ std::string output = \"\"; std::string input = \"l\"; std::string expected = \"L\"; _parser-&gt;convertToUpperCase(input, output); ASSERT_EQ(output, \"L\");}On notera que le test pr√©voit l‚Äôutilisation du type MyParser_t ‚Äì √† d√©finir dans le code √† produire ‚Äì pour stocker l‚Äôinstance unique de MyParser.Bonne nouvelle, les tests √©chouent dans un premier temps, puis (apr√®s plusieurs essais), les modifications suivantes permettent de les valider.Tout d‚Äôabord le fichier MyParser.h :#ifndef MYPARSER_H#include &lt;string&gt;#include &lt;memory&gt;namespace utils{ class MyParser { public: MyParser(); ~MyParser(); void convertToLowerCase(const std::string &amp;, std::string &amp;); void convertToUpperCase(const std::string &amp;, std::string &amp;); }; typedef std::unique_ptr&lt;MyParser&gt; MyParser_t; MyParser_t&amp; getParser();} // namespace utils#endif // MYPARSER_Hpuis, le fichier MyParser.cpp :#include \"MyParser.h\"using namespace utils;//MyParser::convertToLowerCasevoid MyParser::convertToLowerCase(const std::string &amp;input, std::string &amp;output){ output = \"\"; for (auto c : input) output.push_back(tolower(c));}//MyParser::convertToUpperCasevoid MyParser::convertToUpperCase(const std::string &amp;input, std::string &amp;output){ output = \"\"; for (auto c : input) output.push_back(toupper(c));}//MyParser::MyParserMyParser::MyParser(){}//MyParser::~MyParserMyParser::~MyParser(){}//MyParser_t&amp; utils::getParser()MyParser_t&amp; utils::getParser(){ static MyParser_t p = std::unique_ptr&lt;MyParser&gt;(new MyParser()); return p;}On obtient le r√©sulat suivant apr√®s l‚Äôex√©cution des tests:&gt; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Debug ..## truncated ##build&gt; cmake --build . --config Debug## truncated ##build&gt; ../bin/Debug/toolset_test==========] Running 5 tests from 2 test suites.[----------] Global test environment set-up.[----------] 2 tests from ParserTest[ RUN ] ParserTest.Parser_LowerSingleLetter[ OK ] ParserTest.Parser_LowerSingleLetter (0 ms)[ RUN ] ParserTest.Parser_UpperSingleLetter[ OK ] ParserTest.Parser_UpperSingleLetter (0 ms)[----------] 2 tests from ParserTest (0 ms total)[----------] 3 tests from UniqueParserTest[ RUN ] UniqueParserTest.Parser_UniqueParserIsUnique[ OK ] UniqueParserTest.Parser_UniqueParserIsUnique (0 ms)[ RUN ] UniqueParserTest.Parser_UniqueParserLowerSingleLetter[ OK ] UniqueParserTest.Parser_UniqueParserLowerSingleLetter (0 ms)[ RUN ] UniqueParserTest.Parser_UniqueParserUpperSingleLetter[ OK ] UniqueParserTest.Parser_UniqueParserUpperSingleLetter (0 ms)[----------] 3 tests from UniqueParserTest (0 ms total)[----------] Global test environment tear-down[==========] 5 tests from 2 test suites ran. (0 ms total)[ PASSED ] 5 tests.Le refactoring et l‚Äôajout de la fonction se sont bien d√©roul√©s et l‚Äôensemble des tests unitaires d√©finis depuis le d√©but permettent de controler la qualit√© du code tout au long de la production. Ce qui me permet d‚Äôinsister sur un aspect int√©ressant de l‚Äôapproche TDD : les tests ne sont pas jettables ‚Äî on peut les faire √©voluer, comme tout √† l‚Äôheure avec l‚Äôajout du namespace, mais ce serait dommage de les supprimer car il permettent de contr√¥ler la qualit√© du code.ConclusionLe TDD est une approche et pas une technique toute faite. Ce qui signifie qu‚Äôil faut s‚Äôexercer sur des projets avec rigueur et patience. Plus on s‚Äôexerce, plus on a de bons r√©flexes.M√™me si les styles de programmation et les langages varient et qu‚Äôil est difficile de faire des g√©n√©ralit√©s, on peut quand m√™me d√©finir quelques bonnes pratiques, valables pour tout type de projet. J‚Äôen cite 3 : les tests doivent √™tres simples et exprimables en langage naturel on doit absolument s‚Äôinterdire de faire √©voluer le code sans avoir d√©fini les tests qui permettront de valider la production il faut diversifier au maximum l‚Äôobjet des tests (ne pas tester les m√™mes choses) ‚Äî ce qui sera possible en envisageant le maximum de cas d‚Äôusage possible. Le lecteur pourra consulter les ouvrages sur le sujet pour se faire une id√©e plus compl√®te des m√©thologies TDD.Le code utilis√© dans le post est disponible ici. J‚Äôattends vos commentaires‚Ä¶Resources CMake.org Git : official Website GitHub.com/google/googletest Crascit.com : cmake-gte docs.microsoft.com : CMake projects in visual studio Wikipedia : Test-driven development Kanmeugne‚Äôs Blog : Introduction au TDD (II) ‚Äì le cycle vertueux (code source)" }, { "title": "Introduction au TDD (I) : Mise en place avec googletest", "url": "/posts/introduction-tdd-googletest/", "categories": "software development", "tags": "cmake, c++, tdd", "date": "2021-10-29 00:00:00 +0800", "snippet": "Le TDD ‚Äî abbr√©viation de Test-Driven Development ‚Äî fait r√©f√©rence √† une approche de developpement informatique dans laquelle le code est toujours produit dans le but de valider des tests pr√©alablement d√©finis. Le but de cette approche est de garantir une qualit√© optimale du code √† n‚Äôimporte quelle √©tape du d√©veloppement.Photo by Todd Quackenbush on UnsplashLe MindsetLe d√©veloppeur qui adopte le TDD suit n√©cessairement le cycle suivant : √âcrire des petits tests S‚Äôassurer que les tests √©chouent dans un premier temps √âcrire le code qui permet passer le test S‚Äôassurer que le test passe Nettoyer ou r√©factorer le code S‚Äôassurer que le test passe toujours Retourner √† l‚Äô√©tape 1. Le TDD ‚Äî Test-Driven Development ‚Äî fait r√©f√©rence √† une approche de developpement informatique dans laquelle le code est toujours produit dans le but de valider des tests pr√©alablement d√©finis. Le but de cette approche est de garantir une qualit√© optimale du code √† n‚Äôimporte quelle √©tape du d√©veloppement.Mise en situation : d√©veloppement de la lib toolsetLe TDD est une approche rigoureuse qui peut √™tre co√ªteuse √† mettre en oeuvre, mais qui apporte beaucoup de s√©r√©nit√© pour les developpeurs sur le long terme. Dans ce post, je propose un petit tutoriel pour s‚Äôinitier √† l‚Äôapproche TDD. On fera semblant de d√©velopper une biblioth√®que C++ en utilisant les technologies suivantes : CMake pour le packaging (√† installer) googletest pour la gestion des tests unitaires Git pour l‚Äôint√©gration continue et la gestion de version (√† installer)La biblioth√®que contiendra un parser avec les fonctionnalit√©s suivantes: convertToLowerCase : convertit un mot ou une phrase en minuscule convertToUpperCase : convertit un mot ou une phrase en majusculeLe but de cet exercice est d‚Äôappr√©hender les bonnes pratiques du TDD et de comprendre leur int√©r√™t.Le test zero : il faut que √ßa compile !La premi√®re contrainte que l‚Äôon se fixe c‚Äôest de pouvoir lancer les commandes ci-dessous, car le test de compilation est le test le plus fondamental! &gt; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Debug .. &gt; cmake --build . --config Debug &gt; ../bin/Debug/toolset_test Le test de compilation est le test le plus fondamental !Cela suppose de d√©finir les bonnes cibles pour la lib toolset et pour les tests unitaires.Organisation du workspacePour attaquer la production du code qui permettra de valider le test zero, partons de l‚Äôarborescence ci-dessous, qui organise le projet en deux sous projets : un pour les tests et un autre pour la lib toolset.project‚îú‚îÄ‚îÄ CMakeLists.txt # makefile global‚îú‚îÄ‚îÄ bin # stockage des executables‚îú‚îÄ‚îÄ lib # stockage des librairies‚îú‚îÄ‚îÄ build # fichiers de builds‚îú‚îÄ‚îÄ deps # definitions des d√©pendances externes‚îú‚îÄ‚îÄ tests‚îÇ ‚îú‚îÄ‚îÄ CMakeLists.txt # makefile pour les tests‚îÇ ‚îú‚îÄ‚îÄ include‚îÇ ‚îî‚îÄ‚îÄ src‚îî‚îÄ‚îÄ toolset ‚îú‚îÄ‚îÄ CMakeLists.txt # makefile pour la lib ‚îú‚îÄ‚îÄ include ‚îî‚îÄ‚îÄ src Le projet s‚Äôorganise en deux sous projets. Un pour la lib toolset et un autre pour les tests.Les sources pour d√©finir la lib toolset et l‚Äôex√©cutable de tests sont stock√©es respectivement dans les dossiers toolset/ et tests/. Le makefile global du projet est d√©fini dans ./CMakeLists.txt, √† la racine du dossier.Makefile global du projet# CMakeList.txt : Upper level configuration filecmake_minimum_required (VERSION 3.8)# global pathsset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/bin/${CMAKE_BUILD_TYPE}/)set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/lib/${CMAKE_BUILD_TYPE}/)set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/lib/${CMAKE_BUILD_TYPE}/)# project declarationproject (toolset C CXX)# sub projectsadd_subdirectory (\"toolset\")add_subdirectory(\"tests\") Les lignes 4‚Äî10 de ./CMakeLists.txt d√©finissent les chemins par d√©faut pour les cibles et les fichiers interm√©diaires, selon les configurations (Release ou Debug), et suivant les architectures. Les lignes 14‚Äî16 indiquent que le projet contient deux sous-projets : un pour les tests et l‚Äôautre pour la lib toolset.Bien √©videmment dans l‚Äô√©tat actuel, la compilation √©choue puisque les dossiers des sous-projets sont vides. Pour les configurer, on commence par remplir le fichier ./toolset/CMakeLists.txt.Makefile pour la cible toolsetcmake_minimum_required (VERSION 3.8)set(BINARY ${CMAKE_PROJECT_NAME})################################# organize include and src filesset(TOOLSET_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/include/)set(TOOLSET_INCLUDE_DIR ${TOOLSET_INCLUDE_DIR} PARENT_SCOPE)file(GLOB_RECURSE TOOLSET_SRC_FILES ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp)include_directories(${TOOLSET_INCLUDE_DIR})add_library(${BINARY} ${TOOLSET_SRC_FILES}) Le fichier indique que les ent√™tes se trouvent dans le dossier ./toolset/include/ (ligne 9) et les sources, dans le dossier ./toolset/src/ (lignes 8 et 10). Le nom de la cible est indiqu√© √† la ligne 11 en utilisant la varibale ${CMAKE_PROJECT_NAME}, d√©finie dans le CMakeLists.txt global du projet.Apr√®s le makefile de la lib toolset, on remplit le fichier ./tests/CMakeLists.txt pour les tests unitaires. Pour cela, on se sert d‚Äôune astuce qui consiste √† d√©finir googletest comme une d√©pendance ext√©rieure et √† g√©n√©rer toutes ses cibles au moment de la configuration ‚Äî la d√©pendance √† googletest est d√©clar√©e dans un fichier de configuration interm√©diaire, ./deps/gtest/CMakeLists.txt.in.Makefile pour les testscmake_minimum_required (VERSION 3.8)set(BINARY ${CMAKE_PROJECT_NAME}_test)################################## Configure and build GoogleTestconfigure_file( ${CMAKE_SOURCE_DIR}/deps/gtest/CMakeLists.txt.in ${CMAKE_SOURCE_DIR}/build/googletest-download/CMakeLists.txt)execute_process( COMMAND ${CMAKE_COMMAND} -G ${CMAKE_GENERATOR} . RESULT_VARIABLE result WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}/build/googletest-download)if(result) message(FATAL_ERROR \"CMake step for googletest failed: ${result}\")endif()execute_process( COMMAND ${CMAKE_COMMAND} --build . RESULT_VARIABLE result WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}/build/googletest-download)if(result) message(FATAL_ERROR \"Build step for googletest failed: ${result}\")endif()# Prevent overriding the parent project's compiler/linkerset(gtest_force_shared_crt ON CACHE BOOL \"\" FORCE)add_subdirectory( ${CMAKE_SOURCE_DIR}/build/googletest-src ${CMAKE_SOURCE_DIR}/build/googletest-build)################################## organize include and src filesset( GTEST_INCLUDE_DIR ${CMAKE_SOURCE_DIR}/build/googletest-src/googlemock/include/ ${CMAKE_SOURCE_DIR}/build/googletest-src/googletest/include/)set( TEST_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/include/)file( GLOB_RECURSE ${TEST_SRC_FILES} ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp)include_directories( ${GTEST_INCLUDE_DIR} ${TEST_INCLUDE_DIR} ${TOOLSET_INCLUDE_DIR})add_executable (${BINARY} ${TEST_SRC_FILES})target_link_libraries(${BINARY} ${CMAKE_PROJECT_NAME} gmock_main) le makefile des tests fait appel √† une d√©pendance ext√©rieure (ligne 5) pour g√©n√©rer les ent√™tes et les cibles de googletest √† la configuration (lignes 5‚Äî30). La cible pour l‚Äôex√©cutable des tests est compl√®tement d√©finie de la ligne 51 ‚Äî 52.Le fichier ./tests/CMakeLists.txt.in utilis√© pour la d√©pendence √† googletest indique le lien github officiel des sources et le tag √† utiliser.cmake_minimum_required (VERSION 3.8)project(googletest-download NONE)include(ExternalProject)ExternalProject_Add(googletest GIT_REPOSITORY https://github.com/google/googletest GIT_TAG release-1.10.0 SOURCE_DIR \"${CMAKE_SOURCE_DIR}/build/googletest-src\" BINARY_DIR \"${CMAKE_SOURCE_DIR}/build/googletest-build\" CONFIGURE_COMMAND \"\" BUILD_COMMAND \"\" INSTALL_COMMAND \"\" TEST_COMMAND \"\") Le fichier ./deps/gtest/CMakeLists.txt.in est utilis√© dans ./tests/CMakeLists.txt au moment de la configuration et de la cr√©ation des cibles googletest. Il indique le lien github pour r√©cup√©rer les sources et le tag √† utiliser.Code source TDD‚ÄìcompatibleDans l‚Äô√©tat actuel, la production de code ne valide toujours pas le test zero . Notamment, la commande :&gt; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Debug ..renvoie un code d‚Äôerreur car les fichiers sources pour les sous projets tests et toolset sont inexistants! On compl√®te l‚Äôinitialisation du projet avec le strict minimum pour pouvoir valider la compilation.Premi√®rement, le header ./toolset/include/MyParser.h pour d√©clarer le parser :#ifndef MYPARSER_Hclass MyParser;#endif // MYPARSER_HEnsuite, le fichier source ./toolset/src/MyParser.cpp, qui ne contient qu‚Äôune ligne pour l‚Äôinstant :#include \"MyParser.h\"Enfin, le fichier source./tests/src/main.cpp pour la d√©finition et l‚Äôex√©cution des tests :#include &lt;gmock/gmock.h&gt;using namespace testing;int main(int argc, char** argv){ testing::InitGoogleMock(&amp;argc, argv); return RUN_ALL_TESTS();}Validation du test zeroLa production de code fournie ci-dessus valide notre test zero ! La commande cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Debug .. g√©n√®re un makefile syst√®me (ou fichier .sln sous windows avec visual studio), et la commande cmake --build . --config Debug g√©n√®re les bonnes cibles comme on peut le voir sur l‚Äôarborescence ci-dessous..‚îú‚îÄ‚îÄ bin‚îÇ ‚îî‚îÄ‚îÄ Debug‚îÇ ‚îî‚îÄ‚îÄ toolset_test‚îú‚îÄ‚îÄ CMakeLists.txt‚îú‚îÄ‚îÄ deps‚îÇ ‚îî‚îÄ‚îÄ gtest‚îÇ ‚îî‚îÄ‚îÄ CMakeLists.txt.in‚îú‚îÄ‚îÄ lib‚îÇ ‚îî‚îÄ‚îÄ Debug‚îÇ ‚îî‚îÄ‚îÄ libtoolset.a‚îú‚îÄ‚îÄ tests‚îÇ ‚îú‚îÄ‚îÄ CMakeLists.txt‚îÇ ‚îî‚îÄ‚îÄ src‚îÇ ‚îî‚îÄ‚îÄ main.cpp‚îî‚îÄ‚îÄ toolset ‚îú‚îÄ‚îÄ CMakeLists.txt ‚îú‚îÄ‚îÄ include ‚îÇ ‚îî‚îÄ‚îÄ MyParser.h ‚îî‚îÄ‚îÄ src ‚îî‚îÄ‚îÄ MyParser.cpp R√©sultat de la commande cmake --build . --config Debug sur une machine ubuntu avec gcc-7.5. La lib toolset ‚Äî ./lib/Debug/libtoolset.a ‚Äî est correctement g√©n√©r√©e ainsi que l‚Äôex√©cutable pour les tests ‚Äî ./bin/Debug/toolset.Pour l‚Äôinstant lorsqu‚Äôon lance l‚Äôex√©cutable de tests on obtient un message qui nous indique qu‚Äôaucun test n‚Äôa √©t√© d√©fini ‚Äî ce qui est tout √† fait normal. La suite de l‚Äôexercice consiste √† d√©finir les tests unitaires qui permettront de valider chacune des fonctionnalit√©s de la lib toolset √† terme.&gt; ./bin/Debug/toolset[==========] Running 0 tests from 0 test suites.[==========] 0 tests from 0 test suites ran. (0 ms total)[ PASSED ] 0 tests. Les sources sont disponibles sur github, pour les impatients.Maintenant que la mise en place de l‚Äôespace de travail est faite, on peut v√©ritablement entrer dans le cycle vertueux des TDD.ConclusionLe plus dur du travail est fait avec cette mise en place. C‚Äôest tr√®s important de valider le test zero car c‚Äôest la condition n√©cessaire pour travailler it√©rativement par la suite.Dans la deuxi√®me partie de cet exercice, on va se concentrer sur l‚Äôimpl√©mentation des fonctionnalit√©s de la lib. On verra que l‚Äôapproche TDD eprmet d‚Äôenvisager sereinement l‚Äô√©volution du code et le refactoring.Resources CMake.org Git : official Website GitHub.com/google/googletest Crascit.com : cmake-gte docs.microsoft.com : Cmake projects in visual studio Wikipedia : Test-driven development Kanmeugne‚Äôs Blog : Introduction au TDD (I) ‚Äì Mise en place avec googletest (code source) Kanmeugne‚Äôs Blog : Introduction aux TDD (II) ‚Äì Le cycle vertueux" }, { "title": "Pheromon evaporation on a 2D Grid", "url": "/posts/pheromons-evaporation/", "categories": "modeling & simulation", "tags": "sfml, cmake, c++, modeling, pheromon, evaporation, simulation", "date": "2020-10-12 00:00:00 +0800", "snippet": "You should now be familiar with our 2D Grid app. In a previous post, I updated its original object-oriented architecture in order to implement an affordable obstacle feature. Here, I am going to upgrade the architecture again in order to implement a pheromon evaporation feature.Photo by Danny Howe on UnsplashYou can see pheromon like a chemical substance that is dropped somewhere ‚Äî as a mark of an organic activity ‚Äî and then evaporates overtime. Pheromon paradigm is a very productive way to implement a stigmergic behavior ‚Äî which is a type of behavior based on indirect communication through a common and shared space. Stigmergy explains the emergence of collective behavior among several social species with limited intellectual abilities. The concept has been first introduced by the french biologist Pierre-Paul Grass√© and systematically studied by Deneubourg for different ants species.The proposed improvements of the previous object-oriented architecture will focus on mimicking and illustrating an ant-like pheromon evaporation. Simply put, I am going to do the following : add another viewer for pheromon ‚Äî PheromonViewer ‚Äî and more controls in the App object ‚Äì App::addPheromon upgrade IGrid, and consequently Grid, to declare and implement pheromon related methods define a new method ‚Äî App::evaporate ‚Äî responsible of the evaporation process. Fig. 1. Architecture of our 2D Grid Appsfml2dgrid.‚îú‚îÄ‚îÄ CMakeLists.txt‚îú‚îÄ‚îÄ deps‚îÇ ‚îî‚îÄ‚îÄ sfml‚îÇ ‚îî‚îÄ‚îÄ CMakeLists.txt.in‚îî‚îÄ‚îÄ sfml2dgrid ‚îú‚îÄ‚îÄ CMakeLists.txt ‚îú‚îÄ‚îÄ main.cpp ‚îú‚îÄ‚îÄ app ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ include ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ App.h ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ dynamics.h ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ src ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ App.cpp ‚îú‚îÄ‚îÄ env ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ include ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ Grid.h ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ IGrid.h ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ src ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ Grid.cpp ‚îú‚îÄ‚îÄ geometry ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ include ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ geometry.h ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ src ‚îî‚îÄ‚îÄ viewers ‚îú‚îÄ‚îÄ include ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ AbstractViewer.h ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ GridViewer.h ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ObstacleViewer.h ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ PheromonViewer.h ‚îî‚îÄ‚îÄ src ‚îú‚îÄ‚îÄ AbstractViewer.cpp ‚îú‚îÄ‚îÄ GridViewer.cpp ‚îú‚îÄ‚îÄ ObstacleViewer.cpp ‚îî‚îÄ‚îÄ PheromonViewer.cpp The file tree of the project with the source (.cpp) and header (.h) files. I am just going to discuss about the upgrade that I made from the previous version.Pheromon modeling and evaporationThe App object is augmented with App::addPheromon and App::evaporate methods both responsible of adding a little amount of pheromon in a selected cell, and evaporating pheromons over time ‚Äî see Fig. 2. Fig. 2. App and IGrid improvementsApp::evaporate will take a time interval as parameter in order to schedule the evaporation process ‚Äî I use SFML clocks to implement this.App.h#ifndef APP_H#define APP_Hnamespace sf{\tclass RenderWindow;};namespace env{\tclass IGrid;};namespace viewers{\tclass AbstractViewer;};class App{private:\t// sfml render window\tsf::RenderWindow *_window = nullptr;\t// the 2D grid pointer\tenv::IGrid *_grid = nullptr;\t// a pointer to the viewer\t// this could be a set of viewer actually\t// if we consider component behavior\tviewers::AbstractViewer *_viewer = nullptr;public:\t// theorical width of the environment\t// will match the grid width in terms of number of cells.\tstatic const int DEFAULT_WIDTH;\t// theorical height of the environment.\tstatic const int DEFAULT_HEIGHT;\t// x-resolution of the grid i.e. the x-size of a cell\tstatic const int DEFAULT_RESX;\t// y-resolution of the grid i.e. the y-size of a cell\tstatic const int DEFAULT_RESY;\t// attach window to the app\tvoid setWindow(sf::RenderWindow *);\t// attach a specific viewer\tvoid setViewer(viewers::AbstractViewer *);\t// attach a grid (should have been initialized)\tvoid setGrid(env::IGrid *);\t// return the attached grid\tenv::IGrid *getGrid();\t// return the attached window\tsf::RenderWindow *getWindow();\t// run the application (the logic)\tvoid run();\t// show content (display routines)\tvoid display();\t// evaporation cycle\tvoid evaporate();\t// add obstacle control\tbool addObstacle(int, int);\t// remove obstacle control\tbool removeObstacle(int, int);\t// add Pheromon\tbool addPheromon(int, int);\tApp() = default;\tvirtual ~App();};#endif // !APP_HA special method to apply evaporation is also defined in IGrid ‚Äî IGrid::iUpdatePheromon.IGrid.h#ifndef IGRID_H#define IGRID_Hnamespace env{ struct CELL { int _id; // id of the cell bool _mask; float _tau; // amount of pheromon CELL() = default; CELL(const CELL &amp;) = default; }; // Functor definition to apply on cell // We can inherit from this to function // to apply on cells class ICellFunctor { public: virtual void operator()( const CELL &amp; // cell_id ) = 0; }; // IGrid class IGrid { public: virtual ~IGrid() = default; // returns the width virtual int iGetSizeX() const = 0; // returns the height virtual int iGetSizeY() const = 0; // returns the number of cells in the grid virtual int iGetNumberOfCells() const = 0; // gets the width of a cell (in terms of pixels) virtual int iGetResolutionX() const = 0; // gets the height of a cell (in terms of pixels) virtual int iGetResolutionY() const = 0; // applies functor on Cells virtual void iApplyOnCells(ICellFunctor &amp;) const = 0; //-- Test // relative position of a cell according to its id virtual bool iGetCellPosition( const CELL &amp;, // cell int &amp;, // posx int &amp; // posy ) const = 0; // coordinates of a cell accoring to its id virtual bool iGetCellCoordinates( const CELL &amp;, // cell int &amp;, // row_number int &amp; // column_number ) const = 0; // cell rank of the the cell according // to its relative position in the grid virtual bool iGetCellNumber( int, // row_number int, // column_number CELL &amp;) const = 0; // the containing cell given the coordinates in the 2D space virtual bool iGetContainingCell( int, // posx int, // posy CELL &amp; // cell ) const = 0; // checks if a given point is within a given cell virtual bool iIsWithinCell( int, // posx int, // posy const CELL &amp; // cell ) const = 0; // initializes the vector of cells, obstacle mask, etc. virtual void iInitialize() = 0; // add obstacle to the grid virtual bool iAddObstacle(const CELL &amp;) = 0; // remove obstacle from the grid virtual bool iRemoveObstacle(const CELL &amp;) = 0; // return the obstacle status : true if obstacle, false otherwise virtual bool iIsObstacle(const CELL &amp;) const = 0; // pheromons virtual bool iAddPheromon( const CELL &amp;,// cell no const float // pheromon deposit ) = 0; virtual void iUpdatePheromon(const int&amp;) = 0; };} // namespace env#endif // !IGRID_HBasically, IGrid::iUpdatePheromon will update the amount of pheromons for each cell ‚Äî CELL::tau ‚Äî by running the following formula:\\[\\tau_{ij}^{t} = \\tau_{ij}^{t-1} \\cdot (1 - \\rho) + \\Delta^{t}\\tau_{ij}\\]Where : \\(\\tau_{ij}^{t}\\) is the amount of pheromons in \\(cell_{ij}\\) in the current timestep \\(\\tau_{ij}^{t-1}\\) is the amount of pheromons in \\(cell_{ij}\\) in the previous timestep \\(\\Delta^{t}\\tau_{ij}\\) is the amount of pheromon injected in the current timestep \\(\\rho \\in [0,1]\\) is the evaporation coefficientAs you might have guessed, this method will be called in App::evaporate at specific time intervals.ParametersFor numerical robustness, I will use the following global parameters in the implementation: \\(P_{max}\\) : the pheromon maximum capacity of a cell \\(P_{min}\\) : the pheromon minimal capacity of a cell (below this value, the amount of pheromon is set to \\(0\\))The interested reader can refer to the source code to check/set the value for parameters : \\(\\rho, P_{min}\\) and \\(P_{max}\\)PheromonViewerTo visualize pheromons and especially the evaporation process, I added a PheromonViewer that will be called in the App::display method. PheromonViewer::iDraw applies an ICellFunctor on every cell of the grid ‚Äî if their corresponding amount of pheromon is greater than zero ‚Äî that draws a red mark on the screen according to their current state.Fig. 3.ViewerMgr is a meta viewer that agregates more than one viewer. It will be used to add a viewer for pheromon (PheromonViewer) next to the viewers forlines (GridViewer) and obstacles (ObstacleViewer) without changing the relationship between App and AbstractViewerPheromonViewer.h#ifndef PHEROMONVIEWER_H#define PHEROMONVIEWER_H#include \"AbstractViewer.h\"namespace env{ class ICellFunctor;};namespace viewers{ class PheromonViewer : public AbstractViewer { public: PheromonViewer() = default; virtual ~PheromonViewer() = default; protected: virtual void iDraw(); private: void drawPheromon(env::ICellFunctor &amp;); };} // namespace viewers#endif // !PHEROMONVIEWER_HDemoWe are ready to instanciate our brand new App object with all the improvements for pheromon manipulation.main.cpp#include \"App.h\"#include \"GridViewer.h\"#include \"ObstacleViewer.h\"#include \"PheromonViewer.h\"#include \"Grid.h\"#include &lt;thread&gt;#include &lt;SFML/Graphics.hpp&gt;#ifdef __linux__#include &lt;X11/Xlib.h&gt;#endifint main(){#ifdef __linux__ XInitThreads();#endif // -- sfml windows sf::ContextSettings settings; settings.antialiasingLevel = 10; sf::RenderWindow window( sf::VideoMode( (App::DEFAULT_WIDTH*App::DEFAULT_RESX), (App::DEFAULT_HEIGHT*App::DEFAULT_RESY) ), \"SFML 2D Grid\", sf::Style::Titlebar | sf::Style::Close, settings ); window.clear(sf::Color::White); window.setFramerateLimit(120); window.setActive(false); // -- application App app; app.setWindow(&amp;window); //-- grid 2D env::Grid g; g.setSizeX(App::DEFAULT_WIDTH); g.setSizeY(App::DEFAULT_HEIGHT); g.setResolutionX(App::DEFAULT_RESX); g.setResolutionY(App::DEFAULT_RESY); g.iInitialize(); app.setGrid(&amp;g); //-- viewer viewers::GridViewer gviewer; app.setViewer(&amp;gviewer); gviewer.initialize(); gviewer.iActivate(); // grid obstacles viewers::ObstacleViewer oviewer; oviewer.iActivate(); // pheromons viewers::PheromonViewer pviewer; pviewer.iActivate(); // aggregator viewers::ViewerMgr mgr; mgr.iAddViewer(&amp;oviewer); mgr.iAddViewer(&amp;pviewer); mgr.iAddViewer(&amp;gviewer); app.setViewer(&amp;mgr); mgr.iActivate(); // initialize gviewer (only after having attached it to the App object) gviewer.initialize(); //-- launch application std::thread rendering_thread(&amp;App::display, &amp;app); std::thread evaporation_thread(&amp;App::evaporate, &amp;app); app.run(); rendering_thread.join(); evaporation_thread.join(); return 0;}The interested reader can fork the complete source code from here and run the following in a terminal at the project folder root : # on windows $ cmake -G \"Visual Studio $(Version)\" -S . -B ./build $ cmake --build ./build --config Debug --target app $ ./bin/Debug/app # on linux $ mkdir build $ cd build $ cmake -G \"Unix Makefiles\" .. -DCMAKE_BUILD_TYPE=Debug $ cmake --build ./ --target app $ ../bin/Debug/appThe program should display a clickable 2D Grid where the right-click adds an obstacle on the selected cell and the left-click removes it. With the mouse middle you should be able to drop pheromon on the grid. Once pheromons are dropped they automatically and smoothly start to evaporate.Step by step demo : launching the Pheromon Evaporation SFML App from the terminal (built on ubuntu 18.08 with gcc 7.5)Enjoy and feel free to send me your feedbacks!References SFML::Clock fr.wikipedia.org/wiki/Stigmergie The self-organizing exploratory pattern of the argentine ant - Deneubourg J, Aron S, Goss S et al. kanmeugne/sfml2dgrid : sfml-2d-obstacles-pheromons Kanmeugne‚Äôs Blog : Drawing a 2D Grid with SFML Kanmeugne‚Äôs Blog : 2D Grid with obstacles" }, { "title": "Sur l'importance de l'approche multi-agents pour les d√©veloppeurs", "url": "/posts/masmatters/", "categories": "multi-agent systems", "tags": "sma, stigmergy, mas", "date": "2020-10-08 00:00:00 +0800", "snippet": "Le d√©veloppement informatique a connu d‚Äôimportantes √©volutions ces derni√®res ann√©es.Pour √™tre toujours plus proche des besoins ‚Äî acc√©l√©rer la prise de d√©cision dans les entreprises et les institutions publiques, optimiser les temps de calcul et de de d√©ploiement de nouvelles solutions ‚Äî l‚Äôindustrie de l‚Äôinformatique multiplie les moyens techniques et les approches, faisant √©voluer le m√©tier de d√©veloppeur informatique et le rendant de plus en plus complexe.Photo by Abraham Barrera on UnsplashParmi les diff√©rentes tendances qui d√©terminent l‚Äô√©volution du m√©tier de d√©veloppeur informatique, on peut distinguer : La multiplication des p√©riph√©riques d‚Äôacquisition, de traitement et de restitution de la donn√©e. Ces p√©riph√©riques ou accessoires sont des ordinateurs √† part enti√®re ‚Äî car dot√©s de processeurs et programmables. De par leur petite taille et leur omnipr√©sence dans l‚Äôespace vital des utilisateurs, ces objets permettent de diversifier l‚Äôoffre de services informatiques. Le d√©veloppement des technologies de mise en r√©seau. Internet a compl√®tement chang√© le rapport √† l‚Äôordinateur pour un d√©veloppeur informatique. L‚Äôordinateur ne peut plus √™tre vu comme une ressource de calcul isol√©e et les r√©seaux informatiques sont devenus la norme. La possibilit√© de monter plusieurs centaines de milliers d‚Äôordinateurs en r√©seau et tirer ainsi profit de la somme des ressources de calcul pour l‚Äôex√©cution des programmes informatiques incite √† repenser la mani√®re de les concevoir. L‚Äô√©volution de la complexit√© des solutions informatiques. Pour des raisons √† la fois √©conomiques et techniques, il devient de plus en plus difficile de penser une application sans l‚Äôint√©grer dans un syst√®me d‚Äôinteractions avec des serveurs de base de donn√©es ou d‚Äôapplications tierces. En effet, plusieurs fournisseurs d‚Äôapplications se sp√©cialisent dans des t√¢ches bien pr√©cises accessibles via des interfaces d‚Äôutilisation rendues publiques. Par ailleurs, il n‚Äôest pas toujours possible mat√©riellement, de mettre en place des ressources informatiques r√©unissant toutes les caract√©ristiques n√©cessaires au bon fonctionnement d‚Äôune application (capacit√© de stockage, vitesse d‚Äôex√©cution, communication r√©seau, etc.), d‚Äôo√π le besoin de les sp√©cialiser. Le besoin d‚Äôautomatisation du traitement de l‚Äôinformation et la robotisation massive du travail manuel. L‚Äôinformatique fait de plus en plus de choses pour nous, et ce, sans notre intervention. Des applications M2M (Machine to Machine) se d√©veloppent de plus en plus, promues par les besoins des utilisateurs et la transformation digitale dans les entreprises et les espaces publiques. Les solutions informatiques se veulent plus pro-actives et embarqu√©es. Le facteur humain. L‚Äô√©volution des approches de la programmation et des attentes des utilisateurs est en grande partie due √† une relation de plus en plus √©troite entre la machine et l‚Äôhomme. En effet, les utilisateurs ont tendance √† transposer leurs facult√©s intellectuelles et √©motives sur la machine et s‚Äôattendent √† ce qu‚Äôelle parle le m√™me langage qu‚Äôeux. Les approches du d√©veloppement deviennent par cons√©quent de plus en plus abstraites ‚Äî haut niveau ‚Äî quand il s‚Äôagit de cr√©er des outils informatiques capable d‚Äôinteragir avec les utilisateurs dans leurs t√¢ches quotidiennes. Aujourd‚ÄôhuiLe croisement de ces diff√©rentes tendances entra√Æne un changement de perspectives important pour le m√©tier de d√©veloppeur informatique. L‚Äôautomatisation, la robotisation et l‚Äô√©volution de la complexit√© des solutions informatiques impliquent de savoir mettre en ≈ìuvre des programmes informatiques capables de s‚Äôex√©cuter de mani√®re autonome et d‚Äôinteragir avec d‚Äôautres programmes en tenant compte des int√©r√™ts des utilisateurs objectivement exprim√©s. Les r√©seaux informatiques et la distribution des ressources, √©tant devenus la norme, la d√©composition de l‚Äôex√©cution d‚Äôune application en sous programmes et la mise en ≈ìuvre des interactions entre ces diff√©rents programmes sont des pr√©requis incontournables pour le d√©ploiement r√©ussi d‚Äôune application. Prendre les int√©r√™ts d‚Äôun utilisateur ne signifie plus simplement r√©aliser des programmes qui produisent un r√©sultat, mais implique dor√©navant la mise en place de formes de coop√©ration entre programmes, de comp√©tition ou de n√©gociation ‚Äî c‚Äôest donc une √®re tr√®s sociale du d√©veloppement o√π la distribution, les interactions et leur complexit√© se confondent avec les fonctionnalit√©s des solutions informatiques ! Pourquoi les syst√®mes multi-agents ?L‚Äôing√©nieur informatique doit dont penser syst√®me et pas n‚Äôimporte quel syst√®me! L‚Äôing√©nieur doit penser syst√®mes multi-agents (SMA), c‚Äôest-√†-dire, des programmes situ√©s dans des machines et interagissant entre eux pour r√©aliser une t√¢che. Il pourra profiter d‚Äôune abondante litt√©rature sur les actes de langages, les architectures de d√©cision des agents rationnels, des agents r√©actifs, ou encore, des mod√®les d‚Äôaction inspir√©s de la robotique et adapt√©s √† un environnement dynamique. Les SMA offrent au mod√©lisateur informatique une plus grande libert√© de conception pour penser les solutions aux probl√®mes qui lui sont pos√©s et une mani√®re naturelle d‚Äôint√©grer les ressources de calculs et de stockage d√®s la conception.Un autre avantage, et non des moindres, est le parall√®le extr√™mement enrichissant que l‚Äôon peut faire entre les ecosyst√®mes naturels et l‚Äôarchitecture de solutions informatiques. La dimension r√©seau √©tant devenue la norme, comme mentionn√© plus haut, il est possible de s‚Äôinspirer de la nature (fourmis, araign√©es, bact√©ries, plantes, etc. rechercher nature-inspired algorithms) pour imaginer des mod√®les d‚Äôinteractions efficaces entre les programmes.ConclusionVoil√† en quelques mots ce qui me motive √† mettre en avant l‚Äôapproche multi-agent pour les d√©veloppeurs informatique. Bien entendu, il faudra apporter des preuves par la pratique. C‚Äôest pourquoi, tr√®s prochainement, je reviendrai en d√©tails et plus concr√®tement sur l‚Äôint√©r√™t du paradigme SMA pour : le d√©veloppement web l‚Äôapprentissage automatique et l‚Äôoptimisation la simulation comportementaleD‚Äôici-l√†, merci de vos retours." }, { "title": "2D Grid with obstacles", "url": "/posts/2d-grid-obstacles/", "categories": "modeling & simulation", "tags": "sfml, cmake, c++, simulation, modeling", "date": "2020-10-04 00:00:00 +0800", "snippet": "Using a regular 2D Grid to model the navigable space is a good choice if you want to simulate moving agents (ex: vehicules, pedestrians). In fact, 2D Grids can be seen as partitions of the space and, therefore, provide an excellent framework for path planning and collision avoidance algorithms deployment. Moreover, by adding state variables to grid cells, we end up with a very affordable way to manage obstacles and other kind of semantics in the space.Photo by Iewek Gnos on UnsplashIn this post, I am upgrading an existing object oriented architecture that I shared recently as a starting point for those who wanted to have a 2D Grid in their simulation app. Back then, the provided features were limited to grid dimension setting and visualization. In this new version, I am adding a simple obstacle management by attaching state variables to grid cells ‚Äî a complete implementation in C++ is also provided for demonstration. Fig. 1. Architecture of our 2D Grid Appsfml2dgrid.‚îú‚îÄ‚îÄ CMakeLists.txt‚îú‚îÄ‚îÄ deps‚îÇ ‚îî‚îÄ‚îÄ sfml‚îÇ ‚îî‚îÄ‚îÄ CMakeLists.txt.in‚îî‚îÄ‚îÄ sfml2dgrid ‚îú‚îÄ‚îÄ CMakeLists.txt ‚îú‚îÄ‚îÄ main.cpp ‚îú‚îÄ‚îÄ app ‚îÇ ‚îú‚îÄ‚îÄ include ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ App.h ‚îÇ ‚îî‚îÄ‚îÄ src ‚îÇ ‚îî‚îÄ‚îÄ App.cpp ‚îú‚îÄ‚îÄ env ‚îÇ ‚îú‚îÄ‚îÄ include ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Grid.h ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ IGrid.h ‚îÇ ‚îî‚îÄ‚îÄ src ‚îÇ ‚îî‚îÄ‚îÄ Grid.cpp ‚îú‚îÄ‚îÄ geometry ‚îÇ ‚îî‚îÄ‚îÄ include ‚îÇ ‚îî‚îÄ‚îÄ geometry.h ‚îî‚îÄ‚îÄ viewers ‚îú‚îÄ‚îÄ include ‚îÇ ‚îú‚îÄ‚îÄ AbstractViewer.h ‚îÇ ‚îú‚îÄ‚îÄ GridViewer.h ‚îÇ ‚îî‚îÄ‚îÄ ObstacleViewer.h ‚îî‚îÄ‚îÄ src ‚îú‚îÄ‚îÄ AbstractViewer.cpp ‚îú‚îÄ‚îÄ GridViewer.cpp ‚îî‚îÄ‚îÄ ObstacleViewer.cpp The file tree of the project with the source (.cpp) and header (.h) files. I am just going to discuss about the upgrade that I made from the previous version.Comparing to the previous version, I have updated 3 existing objects ‚Äî App, env::IGrid and env::Grid ‚Äî and created 3 new objects ‚Äî viewers::ObstacleViewer, env::ICellFunctor and viewers::ViewerMgr. More details below.AppThe App object is augmented with App::addObstacle and App::removeObstacle both responsible of adding and removing obstacles in the 2D Grid respectively (see Fig. 2). As I teased in the introdution, state variables are associated to grid cells in order to store occupancy information ‚Äî this is how the model handle obstacles : if a cell occupied, it is considered as an obstacle. Fig. 2. App Object (with addObstacle and removeObstacleApp.h#ifndef APP_H#define APP_Hnamespace sf{\tclass RenderWindow;};namespace env{\tclass IGrid;};namespace viewers{\tclass AbstractViewer;};class App{private:\t// sfml render window\tsf::RenderWindow *_window = nullptr;\t// the 2D grid pointer\tenv::IGrid *_grid = nullptr;\t// a pointer to the viewer\t// this could be a set of viewer actually\t// if we consider component behavior\tviewers::AbstractViewer *_viewer = nullptr;public:\t// theorical width of the environment\t// will match the grid width in terms of number of cells.\tstatic const int DEFAULT_WIDTH;\t// theorical height of the environment.\tstatic const int DEFAULT_HEIGHT;\t// x-resolution of the grid i.e. the x-size of a cell\tstatic const int DEFAULT_RESX;\t// y-resolution of the grid i.e. the y-size of a cell\tstatic const int DEFAULT_RESY;\t// attach window to the app\tvoid setWindow(sf::RenderWindow *);\t// attach a specific viewer\tvoid setViewer(viewers::AbstractViewer *);\t// attach a grid (should have been initialized)\tvoid setGrid(env::IGrid *);\t// return the attached grid\tenv::IGrid *getGrid();\t// return the attached window\tsf::RenderWindow *getWindow();\t// run the application (the logic)\tvoid run();\t// show content (display routines)\tvoid display();\t// add obstacle control\tbool addObstacle(int, int);\t// remove obstacle control\tbool removeObstacle (int, int);\tApp() = default;\tvirtual ~App();};#endif // !APP_HIGridThe IGrid interface is augmented with 3 obstacle-related methods ‚Äî IGrid::iAddObstacle, IGrid::iRemoveObstacle and IGrid::iIsObstacle ‚Äî necessary to edit the state of a CELL status (IGrid::iAddObstacle and IGrid::iRemoveObstacle) and to check whether a given CELL is an obstacle or not (IGrid::iIsObstacle).IGrid defines one more method called IGrid::iApplyOnCells which takes a functor on cells ‚Äî env::ICellFunctor ‚Äî as the only parameter and applies it on every cell of the grid. For the record, this method is called in ObstacleViewer::drawObstacles method (see next section), in charge of displaying the obstacles of the grid. Fig. 3 gives extensive details about the IGrid new look and its relations with other classes definitions. Fig. 3. Evolution of the IGrid interface, with 4 more methods :iAddObstacle, iRemoveObstacle, iApplyOnCells and iIsObstacleIGrid.h#ifndef IGRID_H#define IGRID_Hnamespace env{ struct CELL { int _id; // id of the cell bool _mask; CELL() = default; CELL(const CELL &amp;) = default; }; // Functor definition to apply on cell // We can inherit from this to function // to apply on cells class ICellFunctor { public: virtual void operator()( const CELL &amp; // cell_id ) = 0; }; // IGrid class IGrid { public: virtual ~IGrid() = default; // returns the width virtual int iGetSizeX() const = 0; // returns the height virtual int iGetSizeY() const = 0; // returns the number of cells in the grid virtual int iGetNumberOfCells() const = 0; // gets the width of a cell (in terms of pixels) virtual int iGetResolutionX() const = 0; // gets the height of a cell (in terms of pixels) virtual int iGetResolutionY() const = 0; // applies functor on Cells virtual void iApplyOnCells(ICellFunctor &amp;) const = 0; //-- Test // relative position of a cell according to its id virtual bool iGetCellPosition( const CELL &amp;, // cell int &amp;, // posx int &amp; // posy ) const = 0; // coordinates of a cell accoring to its id virtual bool iGetCellCoordinates( const CELL &amp;, // cell int &amp;, // row_number int &amp; // column_number ) const = 0; // cell rank of the the cell according // to its relative position in the grid virtual bool iGetCellNumber( int, // row_number int, // column_number CELL &amp;) const = 0; // the containing cell given the coordinates in the 2D space virtual bool iGetContainingCell( int, // posx int, // posy CELL &amp; // cell ) const = 0; // checks if a given point is within a given cell virtual bool iIsWithinCell( int, // posx int, // posy const CELL &amp; // cell ) const = 0; // initializes the vector of cells, obstacle mask, etc. virtual void iInitialize() = 0; // add obstacle to the grid virtual bool iAddObstacle(const CELL &amp;) = 0; // remove obstacle from the grid virtual bool iRemoveObstacle(const CELL &amp;) = 0; // return the obstacle status : true if obstacle, false otherwise virtual bool iIsObstacle(const CELL &amp;) const = 0; };} // namespace env#endif // !IGRID_HViewerMgr and ObstacleViewerViewerMgr is a special AbstractViewer that agregates (cf. Composite pattern) other AbstractViewer with the method ViewerMgr::iAddViewer. I introduce this pattern in order to separate view concerns and to be able to activate several views at the same time. We will use this meta viewer to attach an ObstacleViewer to the App in order to display the grid lines and the obstacles at the same time. Fig. 4. ViewerMgr is a meta viewer that agregates more than one viewer. It will be used to add a viewer for obstacle (ObstacleViewer) next to the viewer forlines (GridViewer) without changing the relationship between App and AbstractViewerAbstractViewer.h#ifndef ABSTRACTVIEWER_H#define ABSTRACTVIEWER_H#include &lt;vector&gt;class App;namespace viewers{\t// AbstractViewer\tclass AbstractViewer\t{\tpublic:\t\t// activate the viewer. If activated, it provides the desired view\t\tvirtual void iActivate();\t\t// deactivate the viewer. Do not display anaything if deactivated\t\tvirtual void iDeactivate();\t\t// return True if the viewer is active\t\tvirtual bool iIsActive() const;\t\t// display function\t\tvirtual void iDisplay();\t\t// attach the application object\t\tvirtual void iSetApp(App *);\t\tvirtual ~AbstractViewer() = default;\t\tAbstractViewer() = default;\tprotected:\t\t// specific draw method (to be concretized in child classes)\t\tvirtual void iDraw() = 0;\t\tbool _active = false;\t\tApp *_app;\t};\t// viewer manager, using the composite pattern to\t// aggregate several viewers into one\tclass ViewerMgr : public AbstractViewer\t{\tpublic:\t\tvirtual void iAddViewer(AbstractViewer *);\t\tvirtual ~ViewerMgr() = default;\t\tViewerMgr() = default;\t\tvirtual void iSetApp(App *) override;\tprotected:\t\tvirtual void iDraw();\tprivate:\t\tstd::vector&lt;AbstractViewer *&gt; _viewers;\t};} // namespace viewers#endif // ABSTRACTVIEWER_HObstacleViewer.h#ifndef OBSTACLEVIEWER_H#define OBSTACLEVIEWER_H#include \"AbstractViewer.h\"namespace env{ class ICellFunctor;};namespace viewers{ class ObstacleViewer : public AbstractViewer { public: ObstacleViewer() = default; virtual ~ObstacleViewer() = default; protected: virtual void iDraw(); private: void drawObstacles(env::ICellFunctor &amp;); };} // namespace viewers#endif // !OBSTACLEVIEWER_HDemoWe are ready to run our brand new App with all the improvements. The main.cpp for the 2D grid demo App with obstacle management is exactly the following :#include \"App.h\"#include \"GridViewer.h\"#include \"ObstacleViewer.h\"#include \"Grid.h\"#include &lt;thread&gt;#include &lt;SFML/Graphics.hpp&gt;#ifdef __linux__#include &lt;X11/Xlib.h&gt;#endifint main(){#ifdef __linux__ XInitThreads();#endif // -- sfml windows sf::ContextSettings settings; settings.antialiasingLevel = 10; sf::RenderWindow window( sf::VideoMode( (App::DEFAULT_WIDTH*App::DEFAULT_RESX), (App::DEFAULT_HEIGHT*App::DEFAULT_RESY) ), \"SFML 2D Grid with obstacles\", sf::Style::Titlebar | sf::Style::Close, settings ); window.clear(sf::Color::White); window.setFramerateLimit(120); window.setActive(false); // -- application App app; app.setWindow(&amp;window); //-- grid 2D env::Grid g; g.setSizeX(App::DEFAULT_WIDTH); g.setSizeY(App::DEFAULT_HEIGHT); g.setResolutionX(App::DEFAULT_RESX); g.setResolutionY(App::DEFAULT_RESY); g.iInitialize(); app.setGrid(&amp;g); //-- viewer viewers::GridViewer gviewer; gviewer.iActivate(); // grid obstacles viewers::ObstacleViewer oviewer; oviewer.iActivate(); // aggregator viewers::ViewerMgr mgr; mgr.iAddViewer(&amp;oviewer); mgr.iAddViewer(&amp;gviewer); app.setViewer(&amp;mgr); mgr.iActivate(); // initialize gviewer (only after having attached it to the App object) gviewer.initialize(); //-- launch application std::thread rendering_thread(&amp;App::display, &amp;app); app.run(); rendering_thread.join(); return 0;}The interested reader can fork the complete source code from here and run the following in a terminal at the root of the project folder :On windows $ cmake -G \"Visual Studio $(Version)\" -S . -B ./build $ cmake --build ./build --config Debug --target app $ ./bin/Debug/appOn linux $ mkdir build $ cd build $ cmake -G \"Unix Makefiles\" .. -DCMAKE_BUILD_TYPE=Debug $ cmake --build ./ --target app $ ../bin/Debug/appThe program should display a clickable 2D Grid where the right-click adds an obstacle on the selected cell and the left-click removes it.Step by step demo : launching the 2D Grid with obstacles SFML App from the terminal (built on ubuntu 18.08 with gcc 7.5)Enjoy and feel free to send me your feedbacks!References kanmeugne/sfml2dgrid : sfml-2d-obstacles-grid Kanmeugne‚Äôs Blog : Kanmeugne‚Äôs Blog : Drawing a 2D Grid with SFML" }, { "title": "Drawing a 2D Grid with SFML", "url": "/posts/sfml-2d-grid/", "categories": "modeling & simulation", "tags": "sfml, cmake, c++, simulation, modeling", "date": "2020-09-29 00:00:00 +0800", "snippet": "I started studying simulation of moving agents ten years ago and I have come to realize that regular 2D Grids are extraordinary abstractions for the navigable space. In fact, regular 2D grids are very easy to encode and they offer an elegant framework for path planning and collision avoidance algorithms deployment.Photo by Glenn Carstens-Peters on UnsplashIn this post, I am sharing an object oriented architecture ‚Äî with its C++ implementation ‚Äî that I am actually using in my personal projects when I need a 2D Grid. I hope that it could be an affordable starting point for anyone who is interested in the subject.ArchitectureTo be very concrete, I am going to assume that I am building a simulation app ‚Äî of moving agents ‚Äî that uses a 2D grid as the navigable space model. The root object oriented architecture that I am using to tackle the implementation is outlined in Fig. 1. Basically, there is an application object called App and three other packages: env : for the navigable space representation and manipulation objects viewers : for visualisation purposes geometry : for geometrical abstractionI am giving more details about App, env, viewers and geometry below. Fig. 1. Architecture of our 2D Grid Appsfml2dgrid.‚îú‚îÄ‚îÄ CMakeLists.txt‚îú‚îÄ‚îÄ deps‚îÇ ‚îî‚îÄ‚îÄ sfml‚îÇ ‚îî‚îÄ‚îÄ CMakeLists.txt.in‚îî‚îÄ‚îÄ sfml2dgrid ‚îú‚îÄ‚îÄ CMakeLists.txt ‚îú‚îÄ‚îÄ main.cpp ‚îú‚îÄ‚îÄ app ‚îÇ ‚îú‚îÄ‚îÄ include ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ App.h ‚îÇ ‚îî‚îÄ‚îÄ src ‚îÇ ‚îî‚îÄ‚îÄ App.cpp ‚îú‚îÄ‚îÄ env ‚îÇ ‚îú‚îÄ‚îÄ include ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Grid.h ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ IGrid.h ‚îÇ ‚îî‚îÄ‚îÄ src ‚îÇ ‚îî‚îÄ‚îÄ Grid.cpp ‚îú‚îÄ‚îÄ geometry ‚îÇ ‚îî‚îÄ‚îÄ include ‚îÇ ‚îî‚îÄ‚îÄ geometry.h ‚îî‚îÄ‚îÄ viewers ‚îú‚îÄ‚îÄ include ‚îÇ ‚îú‚îÄ‚îÄ AbstractViewer.h ‚îÇ ‚îî‚îÄ‚îÄ GridViewer.h ‚îî‚îÄ‚îÄ src ‚îú‚îÄ‚îÄ AbstractViewer.cpp ‚îî‚îÄ‚îÄ GridViewer.cpp The file tree of the project with the source (.cpp) and header (.h) files that I am going to discuss about in the rest of the postApp : the Application ObjectThe App object is the definition of our application ‚Äî see Fig.2.It holds a viewer (viewers::AbstractViewer) ‚Äî that contains display instructions ‚Äî and a reference to a 2D Grid (env::IGrid) ‚Äî that will be used to manipulate the 2D grid. Note that the App object has an SFML window as a private attribute ‚Äî this is where the rendering will occurs. Fig. 2. App object is attached to a viewer (AbstractViewer) and controls a 2D Grid (IGrid)App also defines two important methods : App::run : responsible of the simulation logic App::display : responsible of the display (what we see on the screen).App.h#ifndef APP_H#define APP_Hnamespace sf{\tclass RenderWindow;};namespace env{\tclass IGrid;};namespace viewers{\tclass AbstractViewer;};class App{private:\t// sfml render window\tsf::RenderWindow *_window = nullptr;\t// the 2D grid pointer\tenv::IGrid *_grid = nullptr;\t// a pointer to the viewer\t// this could be a set of viewer actually\t// if we consider component behavior\tviewers::AbstractViewer *_viewer = nullptr;public:\t// theorical width of the environment\t// will match the grid width in terms of number of cells.\tstatic const int DEFAULT_WIDTH;\t// theorical height of the environment.\tstatic const int DEFAULT_HEIGHT;\t// x-resolution of the grid i.e. the x-size of a cell\tstatic const int DEFAULT_RESX;\t// y-resolution of the grid i.e. the y-size of a cell\tstatic const int DEFAULT_RESY;\t// attach window to the app\tvoid setWindow(sf::RenderWindow *);\t// attach a specific viewer\tvoid setViewer(viewers::AbstractViewer *);\t// attach a grid (should have been initialized)\tvoid setGrid(env::IGrid *);\t// return the attached grid\tenv::IGrid *getGrid();\t// return the attached window\tsf::RenderWindow *getWindow();\t// run the application (the logic)\tvoid run();\t// show content (display routines)\tvoid display();\tApp() = default;\tvirtual ~App();};#endif // !APP_H In the App.h file, I have defined static attributes ‚Äî DEFAULT_WIDTH, DEFAULT_HEIGHT, DEFAULT_RESX, DEFAULT_RESY ‚Äî to set the default dimensions of a grid in the application.AbstractViewer, GridViewer and the geometry PackageAbstractViewer is meant to be derivated according to what we want to show on the application window ‚Äî for instance, GridViewer is a specific implementation of AbstractViewer that uses the geometry package to draw the grid lines.AbstractViewer : The Generic Definition of a ViewerAbstractViewer is always attached to an App object ‚Äî see Fig.3 ‚Äî and defines a protected abstract method called AbstractViewer::iDraw ‚Äî implemented in its inherited classes. AbstractViewer::iDraw is called by the public method AbstractViewer::iDisplay when necessary ‚Äî that will be in the App::display function. Fig. 3. GridViewer is a specific viewer (i.e. inherits from AbstractViewer) in charge of drawing the lines (horizontal and vertical) of the grid. It uses the geometry packageAbstractViewer.h#ifndef ABSTRACTVIEWER_H#define ABSTRACTVIEWER_Hclass App;namespace viewers{\t// AbstractViewer\tclass AbstractViewer\t{\tpublic:\t\t// activate the viewer. If activated, it provides the desired view\t\tvirtual void iActivate();\t\t// deactivate the viewer. Do not display anaything if deactivated\t\tvirtual void iDeactivate();\t\t// return True if the viewer is active\t\tvirtual bool iIsActive() const;\t\t// display function\t\tvirtual void iDisplay();\t\t// attach the application object\t\tvirtual void iSetApp(App *);\t\tvirtual ~AbstractViewer() = default;\t\tAbstractViewer() = default;\tprotected:\t\t// specific draw method (to be concretized in child classes)\t\tvirtual void iDraw() = 0;\t\t// if active the viewer is automatically activated\t\tbool _active = false;\t\t// reference to the attached app\t\tApp *_app;\t};} // namespace viewers#endif // !ABSTRACTVIEWER_H AbstractViewer is always attached to an App object and defines a protected abstract method called AbstractViewer::iDraw.GridViewer : the Grid Lines ViewerFor the exercice, we will define GridViewer as our only viewer, reponsible of displaying the lines of the 2D Grid. The private methods defined in GridViewer are : initialize : to build the set of segments to be displayed drawLine : to call the graphic engine and draw every segment built during the initialization step initialize iDraw : to call the above methods in the right order.GridViewer.h#ifndef GRIDVIEWER_H#define GRIDVIEWER_H#include \"AbstractViewer.h\"#include \"geometry.h\"#include &lt;vector&gt;namespace viewers{\tclass GridViewer : public AbstractViewer\t{\tpublic:\t\tGridViewer() = default;\t\tvirtual void initialize();\t\tvirtual ~GridViewer() = default;\tprotected:\t\tvirtual void iDraw();\tprivate:\t\tvoid drawLines(geometry::ISegmentFunctor &amp;) const;\t\tstd::vector&lt;geometry::Segment&gt; _lines;\t};} // namespace viewers#endif // !GRIDVIEWER_H We define GridViewer as our only viewer, reponsible of displaying the lines of the 2D GridThe geometry PackageHere is the full description of our modest geometry package.It contains the following objects : Point : a 2D point definition, actually a pair of integers Segment : the definition of a segment ‚Äî a pair of Point ISegmentFunctor : an interface, meant to be realised by functors that applies on Segmentgeometry.h#ifndef GEOMETRY_H#define GEOMETRY_H#include &lt;utility&gt;namespace geometry{\t// definition of a point (typedef is sufficient)\ttypedef std::pair&lt;int, int&gt; Point;\t// definition of a segment (typedef is sufficient)\ttypedef std::pair&lt;Point, Point&gt; Segment;\t// Functor definition to apply on segment\t// We can inherit from this to function\t// to apply display instruction on segments\tclass ISegmentFunctor {\tpublic:\t\t// operator function to apply on each segment \t\t// (should concretized according to the need)\t\tvirtual void operator()(\t\t\tconst Segment&amp; // cell_id\t\t) = 0;\t};}#endif // !GEOMETRY_H Our very modest geometry package contains geometry::Point, geometry::Segment and geometry::ISegmentFunctor.The 2D GridThe most important features of our 2D grid are defined in the IGrid interface ‚Äî see Fig.4. IGrid is realized by the Grid object which is composed of grid cells ‚Äî note that the CELL object is defined in IGrid.h. Fig. 4. Grid realizes the interface of a 2D grid, defined in IGridIGrid.h#ifndef IGRID_H#define IGRID_Hnamespace env{\tstruct CELL\t{\t\tint _id; // id of the cell\t\tCELL() = default;\t\tCELL(const CELL &amp;) = default;\t};\tclass IGrid\t{\tpublic:\t\tvirtual ~IGrid() = default;\t\t// returns the width\t\tvirtual int iGetSizeX() const = 0;\t\t// return the height\t\tvirtual int iGetSizeY() const = 0;\t\t// return the number of cells in the grid\t\tvirtual int iGetNumberOfCells() const = 0;\t\t// get the width of a cell (in terms of pixels)\t\tvirtual int iGetResolutionX() const = 0;\t\t// get the height of a cell (in terms of pixels)\t\tvirtual int iGetResolutionY() const = 0;\t\t//-- Test\t\t// relative position of a cell according to its id\t\tvirtual bool iGetCellPosition(\t\t\tconst CELL &amp;, // cell\t\t\tint &amp;, // posx\t\t\tint &amp;, // posy\t\t) const = 0;\t\t// coordinates of a cell accoring to its id\t\tvirtual bool iGetCellCoordinates(\t\t\tconst CELL &amp;, // cell\t\t\tint &amp;, // row_number\t\t\tint &amp; // column_number\t\t) const = 0;\t\t// cell rank of the the cell according\t\t// to its relative position in the grid\t\tvirtual bool iGetCellNumber(\t\t\tint, // row_number\t\t\tint, // column_number\t\t\tCELL &amp;) const = 0;\t\t// the containing cell given the coordinates in the 2D space\t\tvirtual bool iGetContainingCell(\t\t\tint, // posx\t\t\tint, // posy\t\t\tCELL &amp; // cell\t\t) const = 0;\t\t// check if a given point is within a given cell\t\tvirtual bool iIsWithinCell(\t\t\tint, // posx\t\t\tint, // posy\t\t\tconst CELL &amp; // cell\t\t) const = 0;\t\t// initialize the vector of cells, obstacle mask, etc.\t\tvirtual void iInitialize() = 0;\t};} // namespace env#endif // !IGRID_H The features of the 2D grid are defined in IGrid.h ‚Äî IGrid.h also contains the definition of the CELL object.Grid.h#ifndef GRID_H#define GRID_H#include \"IGrid.h\"#include &lt;vector&gt;namespace env{\tconst int DEFAULT_GRID_SIZEX = 10;\tconst int DEFAULT_GRID_SIZEY = 10;\tconst int DEFAULT_RESOLUTIONX = 1;\tconst int DEFAULT_RESOLUTIONY = 1;\tclass Grid : public IGrid\t{\tpublic:\t\tvirtual ~Grid() = default;\t\tGrid() = default;\t\t//-- Getters\t\tvirtual int iGetSizeX() const;\t\tvirtual int iGetSizeY() const;\t\tvirtual int iGetNumberOfCells() const;\t\tvirtual int iGetResolutionX() const;\t\tvirtual int iGetResolutionY() const;\t\t// Test\t\tvirtual bool iGetCellPosition(const CELL &amp;, int &amp;, int &amp;) const;\t\tvirtual bool iGetCellCoordinates(const CELL &amp;, int &amp;, int &amp;) const;\t\tvirtual bool iGetCellNumber(int, int, CELL &amp;) const;\t\tvirtual bool iGetContainingCell(int, int, CELL &amp;) const;\t\tvirtual bool iIsWithinCell(int, int, const CELL &amp;) const;\t\tvirtual void iInitialize();\t\t//-- Setters\t\tvoid setSizeX(int);\t\tvoid setSizeY(int);\t\tvoid setResolutionX(int);\t\tvoid setResolutionY(int);\tprivate:\t\tint _sizex = DEFAULT_GRID_SIZEX;\t\tint _sizey = DEFAULT_GRID_SIZEY;\t\tint _resolutionx = DEFAULT_RESOLUTIONX;\t\tint _resolutiony = DEFAULT_RESOLUTIONY;\t\tstd::vector&lt;CELL&gt; _cells;\t};} // namespace env#endif // !GRID_H The Grid object realizes the IGrid interface.DemoOur 2D Grid app architecture is now complete! The build strategy is exactly the same as what we have presented in a previous post ‚Äî we refer the reader to that post for more details. The main file for the demo contains the following :main.cpp#include \"App.h\"#include \"GridViewer.h\"#include \"Grid.h\"#include &lt;thread&gt;#include &lt;SFML/Graphics.hpp&gt;#ifdef __linux__#include &lt;X11/Xlib.h&gt;#endifint main(){#ifdef __linux__ XInitThreads();#endif // -- sfml windows sf::ContextSettings settings; settings.antialiasingLevel = 10; sf::RenderWindow window( sf::VideoMode( (App::DEFAULT_WIDTH*App::DEFAULT_RESX), (App::DEFAULT_HEIGHT*App::DEFAULT_RESY) ), \"SFML 2D Grid\", sf::Style::Titlebar | sf::Style::Close, settings ); window.clear(sf::Color::White); window.setFramerateLimit(120); window.setActive(false); // -- application App app; app.setWindow(&amp;window); //-- grid 2D Grid g; g.setSizeX(App::DEFAULT_WIDTH); g.setSizeY(App::DEFAULT_HEIGHT); g.setResolutionX(App::DEFAULT_RESX); g.setResolutionY(App::DEFAULT_RESY); g.iInitialize(); app.setGrid(&amp;g); //-- viewer GridViewer gviewer; app.setViewer(&amp;gviewer); gviewer.initialize(); gviewer.iActivate(); //-- launch application std::thread rendering_thread(&amp;App::display, &amp;app); app.run(); rendering_thread.join(); return 0;}Configure and BuildThe interested reader can fork the complete source code from here and run the following in a terminal at the root of the project folder :on windows $ cmake -G \"Visual Studio $(Version)\" -S . -B ./build $ cmake --build ./build --config Debug --target app $ ./bin/Debug/appon linux $ mkdir build $ cd build $ cmake -G \"Unix Makefiles\" .. -DCMAKE_BUILD_TYPE=Debug $ cmake --build ./ --target app --config Debug $ ../bin/Debug/appStep by step demo : launching the 2D Grid SFML App from the terminal (built on ubuntu 18.08 with gcc 7.5)You should see a clickable window with a 2D-Grid displayed on it! Enjoy and feel free to send me your feedbacks!References SFML-Dev.org/ GitHub.com/kanmeugne/sfml2dgrid Kanmeugne‚Äôs Blog : Building a Portable C++ Graphical App with CMake" }, { "title": "Building a Portable C++ Graphical App with CMake", "url": "/posts/sfml-cmake-windows/", "categories": "modeling & simulation", "tags": "sfml, cmake, c++, modeling, linux, windows", "date": "2020-09-18 00:00:00 +0800", "snippet": "Few months ago, I found an article that explains how to use GoogleTest and GoogleMock ‚Äî as an external dependency ‚Äî in a CMake project. Since the approach is amazingly straightforward, I have managed to mimic the paradigm and use SFML ‚Äî as an external dependency ‚Äî in a C++ graphical app.Photo by Yannis H on UnsplashThe Idea : build the dependency targets at configuration timeThe main idea is to compile the external project at configure time. This fully integrates it to the build and gives access to all its targets.The original article recommends two sets of definitions to achieve that with googletest : a CMakeLists.txt.in file, which holds the external project references (namely, the official github location) a CMakeLists.txt file, which defines the targets of your application or your library.With SFML as the external project, all I had to do was basically to fill the configuration files with the right url, and define my own target on top of the dependency build. Here is a short presentation of the P.O.C.The WorkspaceA global CMakeLists.txt is located at the root of the folder ‚Äî for lisibility purposes ‚Äî as you can see below. It sets the targets folders for the project. The dependency and the graphical app targets are defined in a sub-project.project/‚îú‚îÄ‚îÄ App‚îÇ ‚îú‚îÄ‚îÄ CMakeLists.txt‚îÇ ‚îú‚îÄ‚îÄ CMakeLists.txt.in‚îÇ ‚îú‚îÄ‚îÄ include‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ App.h‚îÇ ‚îî‚îÄ‚îÄ src‚îÇ ‚îú‚îÄ‚îÄ App.cpp‚îÇ ‚îî‚îÄ‚îÄ main.cpp‚îú‚îÄ‚îÄ CMakeLists.txt‚îú‚îÄ‚îÄ bin‚îú‚îÄ‚îÄ lib‚îî‚îÄ‚îÄ build There is a global CMakeLists.txt file to set the targets folders locations. The graphical app target and the SFML dependency configuration are defined in a sub-folder.The Global CMakeList.txt# CMakeList.txt¬†: Upper level configuration filecmake_minimum_required (VERSION 3.10)set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/bin/${CMAKE_BUILD_TYPE}/)set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/lib/${CMAKE_BUILD_TYPE}/)set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/lib/${CMAKE_BUILD_TYPE}/)project (SFMLCMAKE C CXX)add_subdirectory (\"App\") The dependency and the graphical app targets are defined in a sub-project called App ‚Äî see the next paragraphs for further details.Dependency Location : CMakeList.txt.inCMakeList.txt.in holds the SFML official location data. This file is used during the configuration of graphical app targets.cmake_minimum_required (VERSION 3.8)project(sfml-download NONE)include(ExternalProject)ExternalProject_Add(sfml GIT_REPOSITORY https://github.com/SFML/SFML.git GIT_TAG master SOURCE_DIR \"${CMAKE_SOURCE_DIR}/build/sfml-src\" BINARY_DIR \"${CMAKE_SOURCE_DIR}/build/sfml-build\" CONFIGURE_COMMAND \"\" BUILD_COMMAND \"\" INSTALL_COMMAND \"\" TEST_COMMAND \"\") The SFML official repository is pulled at configuration time.CMakeLists.txt for the targets definitionThis is where the magic is done. This file basically sets the dependency targets to be built at configuration time. Our graphical app target is defined at the end.cmake_minimum_required (VERSION 3.8)project (app C CXX)# build SFML targets ------------configure_file( ${CMAKE_CURRENT_SOURCE_DIR}/CMakeLists.txt.in ${CMAKE_SOURCE_DIR}/build/sfml-download/CMakeLists.txt)execute_process( COMMAND ${CMAKE_COMMAND} -G ${CMAKE_GENERATOR} . RESULT_VARIABLE result WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}/build/sfml-download)if(result) message(FATAL_ERROR \"CMake step for sfml failed: ${result}\")endif()execute_process( COMMAND ${CMAKE_COMMAND} --build . RESULT_VARIABLE result WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}/build/sfml-download)if(result) message(FATAL_ERROR \"Build step for sfml failed: ${result}\")endif()add_subdirectory( ${CMAKE_SOURCE_DIR}/build/sfml-src ${CMAKE_SOURCE_DIR}/build/sfml-build)#----------------------------------set(SFML_INCLUDE_DIR ${CMAKE_SOURCE_DIR}/build/sfml-build/include/)set(APP_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/include/)file(GLOB_RECURSE APP_SRC_FILES ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp)include_directories(${SFML_INCLUDE_DIR} ${APP_INCLUDE_DIR})# app targetadd_executable (app ${APP_SRC_FILES}) if(WIN32 OR WIN64) target_link_libraries(app sfml-window sfml-system sfml-graphics)else() target_link_libraries(app sfml-window sfml-system sfml-graphics pthread X11)endif()source_group(\"src\" FILES ${APP_SRC_FILES})source_group(\"include\" FILES ${APP_INCLUDE_DIR}/*.h) Lines 4 ‚Äî 27 set the dependency build ‚Äî you can see how the CMakeList.txt.in file is consumed at line 5. The graphical app target definition begins at line 34 (the configuration is cross-platform ‚Äì linux and windows).C++ CodeThe main file App/src/main.cpp basically launches two threads : one for the logic of the application ‚Äî the main thread ‚Äî and the other, for the display routines (the SFML window should be initialized in the main thread).main.cpp file#include \"App.h\"#include &lt;thread&gt;#include &lt;SFML/Graphics.hpp&gt;#ifdef __linux__#include &lt;X11/Xlib.h&gt;#endifint main(){#ifdef __linux__ // init X threads XInitThreads();#endif sf::ContextSettings settings; settings.antialiasingLevel = 10;\t const unsigned int width = (App::DEFAULT_WIDTH*App::DEFAULT_RESX); const unsigned int height = (App::DEFAULT_HEIGHT*App::DEFAULT_RESY); sf::RenderWindow window ( sf::VideoMode(width, height), \"SFML &amp; CMAKE\", sf::Style::Titlebar | sf::Style::Close, settings ); window.clear(sf::Color::Cyan); window.setFramerateLimit(120); window.setActive(false); // App definition App app; app.setWindow(&amp;window); std::thread rendering_thread(&amp;App::display, &amp;app); app.run(); rendering_thread.join(); return 0;} The main.cpp file launches two threads : one for the logic of the application and another for the display. The source code is cross-platform (Linux and Windows)Configuration and buildIf you fork the full source code from here (to get App.h and App.cpp), you should be able to type the following lines in a terminal at the root of the project folder.On windows # on windows cmake -G \"Visual Studio $(Version)\" -S . -B ./build -DCMAKE_BUILD_TYPE=Debug .. cmake --build ./build --config Debug --target appOn Linux # on linux mkdir build cd build cmake -G \"Unix Makefiles\" .. -DCMAKE_BUILD_TYPE=Debug cmake --build ./ --target app --config Debug Note: For linux user, you might need to check this first.RunYou should be able to launch the executable located in the bin folder and see a nice (and clickable) cyan window../bin/Debug/appStep by step Demo : launching the SFML app from the terminal. In this tutorial the program is built on ubuntu 18.08 with gcc 7.5Smile! Now you are ready to take your graphical app wherever you want. Enjoy and feel free to send me your feedbacks!References Cmake.org Googletest crascit: CMake-Gtest SFML-Dev.org : compile with cmake GitHub.com/kanmeugne/sfmlcmake" } ]
